#fxn_locations <-  '/usr/local/home/git/r-dh-ecohydro/ELFGEN';
#source(paste(fxn_locations,"elf_rest_token.R", sep = "/"));
#elf_rest_token (site, token)
# to run in knit'r, need to preload token
#token = 'W-THcwwvstkINd9NIeEMrmNRls-8kVs16mMEcN_-jOA';
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
hydrocode = "vahydrosw_wshed_JU3_7490_7400";
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
# Ex: flows <- fn_get_rundata(207885, 402);
#     fn_iha_7q10(flows);
# Get data frame for stashing multirun data
stash <- data.frame();
mostash <- data.frame();
tsstash = FALSE;
featureid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = featureid,
entity_type = "dh_feature"
)
da <- getProperty(inputs, site, model)
inputs <- list(
varkey = "om_model_element",
featureid = featureid,
entity_type = "dh_feature",
propcode = "vahydro-1.0"
)
model <- getProperty(inputs, site, model)
mid = as.numeric(as.character(model[1,]$pid))
inputs <- list(
varkey = "om_element_connection",
featureid = mid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
# Manual elid
elid = as.numeric(as.character(prop[1,]$propvalue))
# Analsyis config
#runids = c(20021,20023);
#runids = c(20051,20054);
runid = 105
wshed_summary_tbl = data.frame(
"Run ID" = character(),
"Segment Name (D. Area)" = character(),
"7Q10/ALF/LF-90" = character(),
"WD (mean/max)" = character(),
stringsAsFactors = FALSE) ;
#pander(odata);
#pander(odata);
omsite = site <- "http://deq2.bse.vt.edu"
dat <- fn_get_runfile(elid, runid, site = omsite,  cached = FALSE);
install.packages(c("callr", "curl", "devtools", "digest", "DT", "ellipsis", "gstat", "httpuv", "knitr", "pkgconfig", "raster", "sf", "tidyr", "tinytex", "TTR"))
library(pander);
library(httr);
library(hydroTSM);
save_directory <- "/var/www/html/files/fe/plots"
#----------------------------------------------
site <- "http://deq2.bse.vt.edu/d.dh"    #Specify the site of interest, either d.bet OR d.dh
#----------------------------------------------
# Load Libraries
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
hydro_tools <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\hydro-tools"
source(paste(github_link,'config.local.private',sep='/'));
source(paste(hydro_tools,"VAHydro-2.0/rest_functions.R", sep = "/"));
source(paste(hydro_tools,"VAHydro-1.0/fn_vahydro-1.0.R", sep = "/"));
source(paste(hydro_tools,"LowFlow/fn_iha.R", sep = "/"));
#retrieve rest token - DISABLED
#fxn_locations <-  '/usr/local/home/git/r-dh-ecohydro/ELFGEN';
#source(paste(fxn_locations,"elf_rest_token.R", sep = "/"));
#elf_rest_token (site, token)
# to run in knit'r, need to preload token
#token = 'W-THcwwvstkINd9NIeEMrmNRls-8kVs16mMEcN_-jOA';
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
hydrocode = "vahydrosw_wshed_JU3_7490_7400";
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
# Ex: flows <- fn_get_rundata(207885, 402);
#     fn_iha_7q10(flows);
# Get data frame for stashing multirun data
stash <- data.frame();
mostash <- data.frame();
tsstash = FALSE;
featureid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = featureid,
entity_type = "dh_feature"
)
da <- getProperty(inputs, site, model)
inputs <- list(
varkey = "om_model_element",
featureid = featureid,
entity_type = "dh_feature",
propcode = "vahydro-1.0"
)
model <- getProperty(inputs, site, model)
mid = as.numeric(as.character(model[1,]$pid))
inputs <- list(
varkey = "om_element_connection",
featureid = mid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
# Manual elid
elid = as.numeric(as.character(prop[1,]$propvalue))
# Analsyis config
#runids = c(20021,20023);
#runids = c(20051,20054);
runid = 105
wshed_summary_tbl = data.frame(
"Run ID" = character(),
"Segment Name (D. Area)" = character(),
"7Q10/ALF/LF-90" = character(),
"WD (mean/max)" = character(),
stringsAsFactors = FALSE) ;
#pander(odata);
#pander(odata);
omsite = site <- "http://deq2.bse.vt.edu"
dat <- fn_get_runfile(elid, runid, site = omsite,  cached = FALSE);
library(pander);
library(httr);
library(hydroTSM);
save_directory <- "/var/www/html/files/fe/plots"
#----------------------------------------------
site <- "http://deq2.bse.vt.edu/d.dh"    #Specify the site of interest, either d.bet OR d.dh
#----------------------------------------------
# Load Libraries
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
hydro_tools <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\hydro-tools"
source(paste(github_link,'config.local.private',sep='/'));
source(paste(hydro_tools,"VAHydro-2.0/rest_functions.R", sep = "/"));
source(paste(hydro_tools,"VAHydro-1.0/fn_vahydro-1.0.R", sep = "/"));
source(paste(hydro_tools,"LowFlow/fn_iha.R", sep = "/"));
#retrieve rest token - DISABLED
#fxn_locations <-  '/usr/local/home/git/r-dh-ecohydro/ELFGEN';
#source(paste(fxn_locations,"elf_rest_token.R", sep = "/"));
#elf_rest_token (site, token)
# to run in knit'r, need to preload token
#token = 'W-THcwwvstkINd9NIeEMrmNRls-8kVs16mMEcN_-jOA';
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
hydrocode = "vahydrosw_wshed_JU3_7490_7400";
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
# Ex: flows <- fn_get_rundata(207885, 402);
#     fn_iha_7q10(flows);
# Get data frame for stashing multirun data
stash <- data.frame();
mostash <- data.frame();
tsstash = FALSE;
featureid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = featureid,
entity_type = "dh_feature"
)
da <- getProperty(inputs, site, model)
inputs <- list(
varkey = "om_model_element",
featureid = featureid,
entity_type = "dh_feature",
propcode = "vahydro-1.0"
)
model <- getProperty(inputs, site, model)
mid = as.numeric(as.character(model[1,]$pid))
inputs <- list(
varkey = "om_element_connection",
featureid = mid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
# Manual elid
elid = as.numeric(as.character(prop[1,]$propvalue))
# Analsyis config
#runids = c(20021,20023);
#runids = c(20051,20054);
runid = 106
wshed_summary_tbl = data.frame(
"Run ID" = character(),
"Segment Name (D. Area)" = character(),
"7Q10/ALF/LF-90" = character(),
"WD (mean/max)" = character(),
stringsAsFactors = FALSE) ;
#pander(odata);
#pander(odata);
library(pander);
library(httr);
library(hydroTSM);
save_directory <- "/var/www/html/files/fe/plots"
#----------------------------------------------
site <- "http://deq2.bse.vt.edu/d.dh"    #Specify the site of interest, either d.bet OR d.dh
#----------------------------------------------
# Load Libraries
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
hydro_tools <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\hydro-tools"
source(paste(github_link,'config.local.private',sep='/'));
source(paste(hydro_tools,"VAHydro-2.0/rest_functions.R", sep = "/"));
source(paste(hydro_tools,"VAHydro-1.0/fn_vahydro-1.0.R", sep = "/"));
source(paste(hydro_tools,"LowFlow/fn_iha.R", sep = "/"));
#retrieve rest token - DISABLED
#fxn_locations <-  '/usr/local/home/git/r-dh-ecohydro/ELFGEN';
#source(paste(fxn_locations,"elf_rest_token.R", sep = "/"));
#elf_rest_token (site, token)
# to run in knit'r, need to preload token
#token = 'W-THcwwvstkINd9NIeEMrmNRls-8kVs16mMEcN_-jOA';
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
hydrocode = "vahydrosw_wshed_JU3_7490_7400";
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
# Ex: flows <- fn_get_rundata(207885, 402);
#     fn_iha_7q10(flows);
# Get data frame for stashing multirun data
stash <- data.frame();
mostash <- data.frame();
tsstash = FALSE;
featureid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = featureid,
entity_type = "dh_feature"
)
da <- getProperty(inputs, site, model)
inputs <- list(
varkey = "om_model_element",
featureid = featureid,
entity_type = "dh_feature",
propcode = "vahydro-1.0"
)
model <- getProperty(inputs, site, model)
mid = as.numeric(as.character(model[1,]$pid))
inputs <- list(
varkey = "om_element_connection",
featureid = mid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
# Manual elid
elid = as.numeric(as.character(prop[1,]$propvalue))
# Analsyis config
#runids = c(20021,20023);
#runids = c(20051,20054);
runid = 106
wshed_summary_tbl = data.frame(
"Run ID" = character(),
"Segment Name (D. Area)" = character(),
"7Q10/ALF/LF-90" = character(),
"WD (mean/max)" = character(),
stringsAsFactors = FALSE) ;
#pander(odata);
#pander(odata);
omsite = site <- "http://deq2.bse.vt.edu"
dat <- fn_get_runfile(elid, runid, site = omsite,  cached = FALSE);
library(pander);
library(httr);
library(hydroTSM);
save_directory <- "/var/www/html/files/fe/plots"
#----------------------------------------------
site <- "http://deq2.bse.vt.edu/d.dh"    #Specify the site of interest, either d.bet OR d.dh
#----------------------------------------------
# Load Libraries
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
hydro_tools <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\hydro-tools"
source(paste(github_link,'config.local.private',sep='/'));
source(paste(hydro_tools,"VAHydro-2.0/rest_functions.R", sep = "/"));
source(paste(hydro_tools,"VAHydro-1.0/fn_vahydro-1.0.R", sep = "/"));
source(paste(hydro_tools,"LowFlow/fn_iha.R", sep = "/"));
#retrieve rest token - DISABLED
#fxn_locations <-  '/usr/local/home/git/r-dh-ecohydro/ELFGEN';
#source(paste(fxn_locations,"elf_rest_token.R", sep = "/"));
#elf_rest_token (site, token)
# to run in knit'r, need to preload token
#token = 'W-THcwwvstkINd9NIeEMrmNRls-8kVs16mMEcN_-jOA';
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
hydrocode = "vahydrosw_wshed_JU3_7490_7400";
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
# Ex: flows <- fn_get_rundata(207885, 402);
#     fn_iha_7q10(flows);
# Get data frame for stashing multirun data
stash <- data.frame();
mostash <- data.frame();
tsstash = FALSE;
featureid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = featureid,
entity_type = "dh_feature"
)
da <- getProperty(inputs, site, model)
inputs <- list(
varkey = "om_model_element",
featureid = featureid,
entity_type = "dh_feature",
propcode = "vahydro-1.0"
)
model <- getProperty(inputs, site, model)
mid = as.numeric(as.character(model[1,]$pid))
inputs <- list(
varkey = "om_element_connection",
featureid = mid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
# Manual elid
elid = as.numeric(as.character(prop[1,]$propvalue))
# Analsyis config
#runids = c(20021,20023);
#runids = c(20051,20054);
runid = 106
wshed_summary_tbl = data.frame(
"Run ID" = character(),
"Segment Name (D. Area)" = character(),
"7Q10/ALF/LF-90" = character(),
"WD (mean/max)" = character(),
stringsAsFactors = FALSE) ;
#pander(odata);
#pander(odata);
omsite = site <- "http://deq2.bse.vt.edu"
dat <- fn_get_runfile(elid, runid, site = omsite,  cached = FALSE);
plot(as.numeric(dat$Qout) ~ as.Date(as.character(dat$thisdate)), ylim = c(0,1000))
quantile(as.numeric(dat$Qout))
quantile(as.numeric(dat$wd_cumulative_mgd))
library(dataRetrieval)
library(lubridate)
library(plyr)
library(zoo)
library(knitr)
library(ggplot2)
library(stats)
library(lfstat)
library(rstudioapi)
library(IHA)
library(PearsonDS)
library(lfstat)
library(scales)
library(readr)
library(httr)
library(dplyr)
library(stringr)
library(RCurl)
library(rgeos)
library(ggmap)
library(ggsn)
library(sp)
library(rlist)
library(tinytex)
mod.phase1 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario1 <- 'CFBASE30Y20180615' #or "p532cal_062211" (phase 5)
mod.phase2 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario2 <- 'CBASE1808L55CY55R45P50R45P50Y' #or "p532cal_062211" (phase 5)
start.date <- '1984-01-01'
end.date <- '2000-12-31'
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
site_url <- "http://deq2.bse.vt.edu/d.dh"
site.or.server <- 'site'
automated_dashboard <- function(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url, site.or.server, start.num = 1, num.reps = NA) {
cbp6_link = paste0(github_link, "/cbp6/code");
setwd(cbp6_link)
#dir.create(paste0('/opt/model/p6/p6_gb604/out/dashboards/', mod.scenario1, '.vs.', mod.scenario2))
dash.output.dir <- paste0('/opt/model/p6/p6_gb604/out/dashboards/', mod.scenario1, '.vs.', mod.scenario2)
metr.output.dir <- paste0('/opt/model/p6/p6_gb604/out/metrics')
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste0(github_link, "/auth.private"));
#load rest username and password, contained in auth.private file
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
info <- read.csv(paste0(cbp6_link, "/data.csv"))
if (is.na(num.reps) == TRUE) {
num.reps <- length(info$riv.seg)
}
base.table <- data.frame()
climatechange.table <- data.frame()
counter <- 279
while (counter <= num.reps) { #change to number of rows on full csv
print(paste('Generating dashboard for segment', counter, 'of', counter+num.reps, sep = ' '))
riv.seg <- as.character(info[counter,1]) #input for model data import
site_number <- paste0("0",info[counter,2]) #input for model data import
rmarkdown::render(paste0("Working_Dashboard_2019.Rmd"), "pdf_document", output_dir = dash.output.dir, output_file = paste0(riv.seg, ".pdf"),
params = list(token = token, riv.seg = riv.seg))
# LOADING DATA ------------------------------------------------------------
# if (site.or.server == 'site') {
#   data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
#   data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
# } else if (site.or.server == 'server') {
#   data1 <- model_server_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
#   data2 <- model_server_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
# }
#
# data1 <- water_year_trim(data1)
# data2 <- water_year_trim(data2)
# metrics1 <- metrics_calc_all(data1) #calculate metrics into a matrix
rownames(metrics1) <- (riv.seg)
# metrics2 <- metrics_calc_all(data2)
rownames(metrics2) <- (riv.seg)
all_metrics <- metrics_compare(metrics1, metrics2, riv.seg)
# table.metrics1 <- data.frame(riv.seg,metrics1[1,1],metrics1[1,67],metrics1[1,61],metrics1[1,59]) #create row to add to overall dataframe
# table.metrics2 <- data.frame(riv.seg,metrics2[1,1],metrics2[1,67],metrics2[1,61],metrics2[1,59]) #create row to add to overall dataframe
# colnames(table.metrics1) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
# colnames(table.metrics2) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
base.table <- rbind(base.table, metrics1, stringsAsFactors = FALSE)
climatechange.table <- rbind(climatechange.table, metrics2, stringsAsFactors = FALSE)
counter <- counter + 1
}
}
automated_dashboard(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url, site.or.server, start.num = 1, num.reps = NA)
# # INPUTS
riv.seg <- 'JA5_7480_0001'
run.id1 <- '122'
run.id2 <- '123'
start.date <- '1984-01-01'
end.date <- '2000-12-31'
github_link <- "C:\\Users\\danie\\Documents\\HARP\\GitHub"
cbp6_link <- paste0(github_link, "/cbp6/code");
site_url <- "http://deq2.bse.vt.edu/d.dh"
site.or.server <- 'site'
site <- site_url
# obsolete inputs
mod.phase1 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario1 <- 'CFBASE30Y20180615' #or "p532cal_062211" (phase 5)
mod.phase2 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario2 <- 'CBASE1808L55CY55R45P50R45P50Y' #or "p532cal_062211" (phase 5)
site_number <- '00000000'
source(paste0(cbp6_link,"/cbp6_functions.R"))
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in
source(paste(cbp6_link, "/fn_vahydro-1.0.R", sep = ''))
source(paste(cbp6_link, "/fn_vahydro-1.0.R", sep = ''))
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
# Should new or original data be used?
new.or.original <- "new"
# CARRYOVER IF MASTER IS BEING RUN ----------------------------------------
if (exists("container.master") == TRUE) {
github_link <- container.master
riv.seg <- riv.seg.master
new.or.original <- new.or.original.master
}
# LOADING DATA ------------------------------------------------------------
if (site.or.server == 'site') {
#data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data1 <- vahydro_import_data_cfs(riv.seg, run.id1, token, site = site_url, start.date, end.date)
#data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data2 <- vahydro_import_data_cfs(riv.seg, run.id2, token, site = site_url, start.date, end.date)
} else if (site.or.server == 'server') {
data1 <- model_server_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data2 <- model_server_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
}
View(data1)
View(data2)
end.date <- '2014-12-31'
#data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data1 <- vahydro_import_data_cfs(riv.seg, run.id1, token, site = site_url, start.date, end.date)
#data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data2 <- vahydro_import_data_cfs(riv.seg, run.id2, token, site = site_url, start.date, end.date)
View(data2)
View(data1)
mean(data1)
mean(data1$flow)
mean(data2$flow)
quantile(data1$flow)
quantile(data2$flow)
