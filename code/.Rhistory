differenceyear[q,4] <- differenceyear[q,1]
differenceyear[q,1]<- differenceyear[q,1] + 1 # year for jan moves
differenceyear[q,2] <- 1
}else if (differenceyear[q,5] == -1) {
differenceyear[q,4] <- differenceyear[q,4] - 1 # if january, go back a year and start november
differenceyear[q,5] <- 11
}else if (differenceyear[q,5] == 0) {
differenceyear[q,4] <- differenceyear[q,4] - 1 # if january, go back a year and start november
differenceyear[q,5] <- 12
} else{
differenceyear[q,1]<- differenceyear[q,1]  #endyear
differenceyear[q,2]<- differenceyear[q,2]  #endmonth
differenceyear[q,4]<- differenceyear[q,4]  #startyear
differenceyear[q,5]<- differenceyear[q,5]  #startmonth
}
differenceyear[q,3]<- paste0(differenceyear[q,1], '-',differenceyear[q,2], '-01') #enddate
differenceyear$enddate <- as.Date(differenceyear$enddate)
differenceyear[q,6]<- as.Date(paste0(differenceyear[q,4], '-', differenceyear[q,5], '-01')) #startdate
differenceyear$startdate <- as.Date(differenceyear$startdate)
differencedates[q,1]<- as.character(differenceyear$startdate[q])
differencedates[q,2]<- as.character(differenceyear$enddate[q]-1)
differencedates[q,3]<- which(as.Date(all_data$Date)==as.Date(differencedates$`start date row`[q]))
differencedates[q,4]<- which(as.Date(all_data$Date)==as.Date(differencedates$`end date row`[q]))
plot1<-all_data[differencedates$V3[q]:differencedates$V4[q],]
if (q==1){
storeplotdata1<- plot1
}else if(q==2){
storeplotdata2<- plot1
}else if(q==3){
storeplotdata3<- plot1
}
q <- q+1
}
# # create and export 3 plots: \plot for info of row q
difference1 <- signif(HighestDifferences$Difference[1], digits=3)     #Create difference variable to display on graph
difference2 <- signif(HighestDifferences$Difference[2], digits=3)
difference3 <- signif(HighestDifferences$Difference[3], digits=3)
# CREATES OUTPUT MATRIX -------------------------------------------------------
avg_scenario1 <- mean(data1$flow)
avg_scenario2 <- mean(data2$flow)
# also want to list the number of timespans that were over 20% difference.
over20 <- signif(nrow(over20)/nrow(Timespan_Difference)*100, digits=3)
OUTPUT_MATRIX <- matrix(c(avg_scenario1, avg_scenario2, over20), nrow=1, ncol=3)
rownames(OUTPUT_MATRIX) = c("Flow")
colnames(OUTPUT_MATRIX) = c('Scenario 1', 'Scenario 2', 'Difference>20 (%)')
overall_difference <- signif((OUTPUT_MATRIX[1,1]-OUTPUT_MATRIX[1,2])/OUTPUT_MATRIX[1,1]*100, digits=3)
OUTPUT_MATRIX <- matrix(c(over20, percent_difference[3,]), nrow=1, ncol=2)
rownames(OUTPUT_MATRIX) = c("Percent")
colnames(OUTPUT_MATRIX) = c('Difference > 20%', 'Overall Difference')
OUTPUT_MATRIX <- signif(as.numeric(OUTPUT_MATRIX, digits = 2))
OUTPUT_MATRIXsaver <- OUTPUT_MATRIX
?paste
?is.character
?readline
?add_headers
??add_headers
?content
??content
# Loading Necessary Packages
library(dataRetrieval)
library(lubridate)
library(plyr)
library(zoo)
library(knitr)
library(ggplot2)
library(stats)
library(lfstat)
library(rstudioapi)
library(IHA)
library(PearsonDS)
library(lfstat)
library(scales)
library(readr)
library(httr)
library(dplyr)
library(stringr)
library(RCurl)
library(rgeos)
library(ggmap)
library(ggsn)
library(sp)
library(rlist)
riv.seg <- 'DE0_3791_0001_0111'
mod.phase1 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario1 <- 'CFBASE30Y20180615' #or "p532cal_062211" (phase 5)
mod.phase2 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario2 <- 'CBASE1808L55CY55R45P50R45P50Y' #or "p532cal_062211" (phase 5)
start.date <- '1984-01-01'
end.date <- '2000-12-31'
site_number <- '01483700'
cbp6_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\cbp6\\code";
site_url <- "http://deq2.bse.vt.edu/d.dh"
area <- readNWISsite(site_number);
area <- area$`drain_area_va` #sq. miles
area <- area*27878400 #sq ft
container1 ="C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github";
container2 = "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\cbp6\\code";
# Sourcing functions
source(paste0(container2,"/cbp6_functions.R"))
# Should new or original data be used?
new.or.original <- "new"
# CARRYOVER IF MASTER IS BEING RUN ----------------------------------------
if (exists("container.master") == TRUE) {
container1 <- container.master
riv.seg <- riv.seg.master
new.or.original <- new.or.original.master
}
data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
# Loading Necessary Packages
library(dataRetrieval)
library(lubridate)
library(plyr)
library(zoo)
library(knitr)
library(ggplot2)
library(stats)
library(lfstat)
library(rstudioapi)
library(IHA)
library(PearsonDS)
library(lfstat)
library(scales)
library(readr)
library(httr)
library(dplyr)
library(stringr)
library(RCurl)
library(rgeos)
library(ggmap)
library(ggsn)
library(sp)
library(rlist)
# INPUTS
riv.seg <- 'EL0_4560_4562'
mod.phase1 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario1 <- 'CFBASE30Y20180615' #or "p532cal_062211" (phase 5)
mod.phase2 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario2 <- 'CBASE1808L55CY55R45P50R45P50Y' #or "p532cal_062211" (phase 5)
start.date <- '1984-01-01'
end.date <- '2000-12-31'
site_number <- '01487000'
cbp6_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\cbp6\\code";
site_url <- "http://deq2.bse.vt.edu/d.dh"
area <- readNWISsite(site_number);
area <- area$`drain_area_va` #sq. miles
area <- area*27878400 #sq ft
# SETUP
# SETUP
# Setting active directory
# Setting working directory to the source file location
container1 ="C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github";
container2 = "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\cbp6\\code";
# Sourcing functions
source(paste0(container2,"/cbp6_functions.R"))
# Should new or original data be used?
new.or.original <- "new"
# CARRYOVER IF MASTER IS BEING RUN ----------------------------------------
if (exists("container.master") == TRUE) {
container1 <- container.master
riv.seg <- riv.seg.master
new.or.original <- new.or.original.master
}
data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data1 <- water_year_trim(data1)
data2 <- water_year_trim(data2)
#retrieve rest token
source(paste0(container1, "/auth.private"));
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
# Loading written gage description
description <- read_file(paste0(cbp6_link, "/gage_descriptions/", site_number, ".txt"))
# Generating gage location maps
gis_img <- fn_gage_and_seg_mapper(riv.seg, site_number, site_url, cbp6_link)
automated_dashboard <- function(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url) {
cbp6_link = paste0(github_link, "\\cbp6\\code");
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste0(github_link, "/auth.private"));
#load rest username and password, contained in auth.private file
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
info <- read.csv(paste0(cbp6_link, "\\data.csv"))
base.table <- data.frame()
climatechange.table <- data.frame()
counter <- 1
while (counter <= 5) { #change to number of rows on full csv
riv.seg <- as.character(info[counter,1]) #input for model data import
site_number <- paste0("0",info[counter,2]) #input for model data import
rmarkdown::render(paste0("Working_Dashboard_2019.Rmd"), "pdf_document", output_dir = cbp6_link, output_file = paste0(riv.seg, ".pdf"),
params = list(token = token, riv.seg = riv.seg))
# LOADING DATA ------------------------------------------------------------
data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data1 <- water_year_trim(data1)
data2 <- water_year_trim(data2)
metrics1 <- metrics_calc_all(data1) #calculate metrics into a matrix
metrics2 <- metrics_calc_all(data2)
all_metrics <- metrics_compare(metrics1, metrics2, riv.seg)
# table.metrics1 <- data.frame(riv.seg,metrics1[1,1],metrics1[1,67],metrics1[1,61],metrics1[1,59]) #create row to add to overall dataframe
# table.metrics2 <- data.frame(riv.seg,metrics2[1,1],metrics2[1,67],metrics2[1,61],metrics2[1,59]) #create row to add to overall dataframe
# colnames(table.metrics1) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
# colnames(table.metrics2) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
base.table <- rbind(base.table, metrics1, stringsAsFactors = FALSE)
climatechange.table <- rbind(climatechange.table, metrics2, stringsAsFactors = FALSE)
counter <- counter + 1
}
write.csv(base.table, file = 'Base_2018_Metrics.csv')
write.csv(climatechange.table, file = 'Climate_Change_Metrics.csv')
}
automated_dashboard('p6/p6_gb604', 'CFBASE30Y20180615', 'p6/p6_gb604', 'CBASE1808L55CY55R45P50R45P50Y', '1984-01-01', '2000-12-31', "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\GitHub\\cbp6\\code", "http://deq2.bse.vt.edu/d.dh")
setwd("C:/Users/Kevin D'Andrea/Desktop/HARP/GitHub/cbp6/code")
automated_dashboard('p6/p6_gb604', 'CFBASE30Y20180615', 'p6/p6_gb604', 'CBASE1808L55CY55R45P50R45P50Y', '1984-01-01', '2000-12-31', "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\GitHub\\cbp6\\code", "http://deq2.bse.vt.edu/d.dh")
automated_dashboard <- function(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url) {
cbp6_link = paste0(github_link, "\\cbp6\\code");
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste0(github_link, "/auth.private"));
#load rest username and password, contained in auth.private file
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
info <- read.csv(paste0(cbp6_link, "\\data.csv"))
base.table <- data.frame()
climatechange.table <- data.frame()
counter <- 1
while (counter <= 5) { #change to number of rows on full csv
riv.seg <- as.character(info[counter,1]) #input for model data import
site_number <- paste0("0",info[counter,2]) #input for model data import
rmarkdown::render(paste0("Working_Dashboard_2019.Rmd"), "pdf_document", output_dir = cbp6_link, output_file = paste0(riv.seg, ".pdf"),
params = list(token = token, riv.seg = riv.seg))
# LOADING DATA ------------------------------------------------------------
data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data1 <- water_year_trim(data1)
data2 <- water_year_trim(data2)
metrics1 <- metrics_calc_all(data1) #calculate metrics into a matrix
metrics2 <- metrics_calc_all(data2)
all_metrics <- metrics_compare(metrics1, metrics2, riv.seg)
# table.metrics1 <- data.frame(riv.seg,metrics1[1,1],metrics1[1,67],metrics1[1,61],metrics1[1,59]) #create row to add to overall dataframe
# table.metrics2 <- data.frame(riv.seg,metrics2[1,1],metrics2[1,67],metrics2[1,61],metrics2[1,59]) #create row to add to overall dataframe
# colnames(table.metrics1) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
# colnames(table.metrics2) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
base.table <- rbind(base.table, metrics1, stringsAsFactors = FALSE)
climatechange.table <- rbind(climatechange.table, metrics2, stringsAsFactors = FALSE)
counter <- counter + 1
}
write.csv(base.table, file = 'Base_2018_Metrics.csv')
write.csv(climatechange.table, file = 'Climate_Change_Metrics.csv')
}
automated_dashboard('p6/p6_gb604', 'CFBASE30Y20180615', 'p6/p6_gb604', 'CBASE1808L55CY55R45P50R45P50Y', '1984-01-01', '2000-12-31', "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\cbp6\\code", "http://deq2.bse.vt.edu/d.dh")
automated_dashboard('p6/p6_gb604', 'CFBASE30Y20180615', 'p6/p6_gb604', 'CBASE1808L55CY55R45P50R45P50Y', '1984-01-01', '2000-12-31', "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github", "http://deq2.bse.vt.edu/d.dh")
mod.phase1 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario1 <- 'CFBASE30Y20180615' #or "p532cal_062211" (phase 5)
mod.phase2 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario2 <- 'CBASE1808L55CY55R45P50R45P50Y' #or "p532cal_062211" (phase 5)
start.date <- '1984-01-01'
end.date <- '2000-12-31'
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
github_link <- "C:\\Users\\danie\\Documents\\HARP\\Github"
site_url <- "http://deq2.bse.vt.edu/d.dh"
site.or.server <- 'site'
automated_dashboard <- function(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url, site.or.server) {
setwd(github_link)
cbp6_link = paste0(github_link, "\\cbp6\\code");
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste0(github_link, "/auth.private"));
#load rest username and password, contained in auth.private file
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
info <- read.csv(paste0(cbp6_link, "\\data.csv"))
base.table <- data.frame()
climatechange.table <- data.frame()
counter <- 1
while (counter <= 5) { #change to number of rows on full csv
riv.seg <- as.character(info[counter,1]) #input for model data import
site_number <- paste0("0",info[counter,2]) #input for model data import
rmarkdown::render(paste0("Working_Dashboard_2019.Rmd"), "pdf_document", output_dir = cbp6_link, output_file = paste0(riv.seg, ".pdf"),
params = list(token = token, riv.seg = riv.seg))
# LOADING DATA ------------------------------------------------------------
data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data1 <- water_year_trim(data1)
data2 <- water_year_trim(data2)
metrics1 <- metrics_calc_all(data1) #calculate metrics into a matrix
metrics2 <- metrics_calc_all(data2)
all_metrics <- metrics_compare(metrics1, metrics2, riv.seg)
# table.metrics1 <- data.frame(riv.seg,metrics1[1,1],metrics1[1,67],metrics1[1,61],metrics1[1,59]) #create row to add to overall dataframe
# table.metrics2 <- data.frame(riv.seg,metrics2[1,1],metrics2[1,67],metrics2[1,61],metrics2[1,59]) #create row to add to overall dataframe
# colnames(table.metrics1) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
# colnames(table.metrics2) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
base.table <- rbind(base.table, metrics1, stringsAsFactors = FALSE)
climatechange.table <- rbind(climatechange.table, metrics2, stringsAsFactors = FALSE)
counter <- counter + 1
}
write.csv(base.table, file = 'Base_2018_Metrics.csv')
write.csv(climatechange.table, file = 'Climate_Change_Metrics.csv')
}
automated_dashboard(mod.phase1,mod.scenario1,mod.phase2,mod.scenario2,start.date,end.date,github_link,site_url,site.or.server)
setwd(github_link)
automated_dashboard <- function(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url, site.or.server) {
cbp6_link = paste0(github_link, "\\cbp6\\code");
setwd(cbp6_link)
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste0(github_link, "/auth.private"));
#load rest username and password, contained in auth.private file
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
info <- read.csv(paste0(cbp6_link, "\\data.csv"))
base.table <- data.frame()
climatechange.table <- data.frame()
counter <- 1
while (counter <= 5) { #change to number of rows on full csv
riv.seg <- as.character(info[counter,1]) #input for model data import
site_number <- paste0("0",info[counter,2]) #input for model data import
rmarkdown::render(paste0("Working_Dashboard_2019.Rmd"), "pdf_document", output_dir = cbp6_link, output_file = paste0(riv.seg, ".pdf"),
params = list(token = token, riv.seg = riv.seg))
# LOADING DATA ------------------------------------------------------------
data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data1 <- water_year_trim(data1)
data2 <- water_year_trim(data2)
metrics1 <- metrics_calc_all(data1) #calculate metrics into a matrix
metrics2 <- metrics_calc_all(data2)
all_metrics <- metrics_compare(metrics1, metrics2, riv.seg)
# table.metrics1 <- data.frame(riv.seg,metrics1[1,1],metrics1[1,67],metrics1[1,61],metrics1[1,59]) #create row to add to overall dataframe
# table.metrics2 <- data.frame(riv.seg,metrics2[1,1],metrics2[1,67],metrics2[1,61],metrics2[1,59]) #create row to add to overall dataframe
# colnames(table.metrics1) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
# colnames(table.metrics2) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
base.table <- rbind(base.table, metrics1, stringsAsFactors = FALSE)
climatechange.table <- rbind(climatechange.table, metrics2, stringsAsFactors = FALSE)
counter <- counter + 1
}
write.csv(base.table, file = 'Base_2018_Metrics.csv')
write.csv(climatechange.table, file = 'Climate_Change_Metrics.csv')
}
automated_dashboard(mod.phase1,mod.scenario1,mod.phase2,mod.scenario2,start.date,end.date,github_link,site_url,site.or.server)
warnings()
??dir
?dir
?create.dir
?write.csv
automated_dashboard <- function(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url, site.or.server) {
cbp6_link = paste0(github_link, "\\cbp6\\code");
setwd(cbp6_link)
dir.create('dashboard comparisons')
output.dir <- paste0(cbp6_link, 'dashboard comparisons')
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste0(github_link, "/auth.private"));
#load rest username and password, contained in auth.private file
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
info <- read.csv(paste0(cbp6_link, "\\data.csv"))
base.table <- data.frame()
climatechange.table <- data.frame()
counter <- 1
while (counter <= 5) { #change to number of rows on full csv
riv.seg <- as.character(info[counter,1]) #input for model data import
site_number <- paste0("0",info[counter,2]) #input for model data import
rmarkdown::render(paste0("Working_Dashboard_2019.Rmd"), "pdf_document", output_dir = output.dir, output_file = paste0(riv.seg, ".pdf"),
params = list(token = token, riv.seg = riv.seg))
# LOADING DATA ------------------------------------------------------------
data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data1 <- water_year_trim(data1)
data2 <- water_year_trim(data2)
metrics1 <- metrics_calc_all(data1) #calculate metrics into a matrix
metrics2 <- metrics_calc_all(data2)
all_metrics <- metrics_compare(metrics1, metrics2, riv.seg)
# table.metrics1 <- data.frame(riv.seg,metrics1[1,1],metrics1[1,67],metrics1[1,61],metrics1[1,59]) #create row to add to overall dataframe
# table.metrics2 <- data.frame(riv.seg,metrics2[1,1],metrics2[1,67],metrics2[1,61],metrics2[1,59]) #create row to add to overall dataframe
# colnames(table.metrics1) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
# colnames(table.metrics2) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
base.table <- rbind(base.table, metrics1, stringsAsFactors = FALSE)
climatechange.table <- rbind(climatechange.table, metrics2, stringsAsFactors = FALSE)
counter <- counter + 1
}
write.csv(base.table, file = paste0(output.dir, '\Base_2018_Metrics.csv'))
write.csv(climatechange.table, file = paste0(output.dir, '\Climate_Change_Metrics.csv'))
}
automated_dashboard <- function(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url, site.or.server) {
cbp6_link = paste0(github_link, "\\cbp6\\code");
setwd(cbp6_link)
dir.create('dashboard comparisons')
output.dir <- paste0(cbp6_link, 'dashboard comparisons')
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste0(github_link, "/auth.private"));
#load rest username and password, contained in auth.private file
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
info <- read.csv(paste0(cbp6_link, "\\data.csv"))
base.table <- data.frame()
climatechange.table <- data.frame()
counter <- 1
while (counter <= 5) { #change to number of rows on full csv
riv.seg <- as.character(info[counter,1]) #input for model data import
site_number <- paste0("0",info[counter,2]) #input for model data import
rmarkdown::render(paste0("Working_Dashboard_2019.Rmd"), "pdf_document", output_dir = output.dir, output_file = paste0(riv.seg, ".pdf"),
params = list(token = token, riv.seg = riv.seg))
# LOADING DATA ------------------------------------------------------------
data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data1 <- water_year_trim(data1)
data2 <- water_year_trim(data2)
metrics1 <- metrics_calc_all(data1) #calculate metrics into a matrix
metrics2 <- metrics_calc_all(data2)
all_metrics <- metrics_compare(metrics1, metrics2, riv.seg)
# table.metrics1 <- data.frame(riv.seg,metrics1[1,1],metrics1[1,67],metrics1[1,61],metrics1[1,59]) #create row to add to overall dataframe
# table.metrics2 <- data.frame(riv.seg,metrics2[1,1],metrics2[1,67],metrics2[1,61],metrics2[1,59]) #create row to add to overall dataframe
# colnames(table.metrics1) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
# colnames(table.metrics2) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
base.table <- rbind(base.table, metrics1, stringsAsFactors = FALSE)
climatechange.table <- rbind(climatechange.table, metrics2, stringsAsFactors = FALSE)
counter <- counter + 1
}
write.csv(base.table, file = paste0(output.dir, '\Base_2018_Metrics.csv'))
write.csv(climatechange.table, file = paste0(output.dir, '\Climate_Change_Metrics.csv'))
}
automated_dashboard <- function(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url, site.or.server) {
cbp6_link = paste0(github_link, "\\cbp6\\code");
setwd(cbp6_link)
dir.create('dashboard comparisons')
output.dir <- paste0(cbp6_link, 'dashboard comparisons')
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste0(github_link, "/auth.private"));
#load rest username and password, contained in auth.private file
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
info <- read.csv(paste0(cbp6_link, "\\data.csv"))
base.table <- data.frame()
climatechange.table <- data.frame()
counter <- 1
while (counter <= 5) { #change to number of rows on full csv
riv.seg <- as.character(info[counter,1]) #input for model data import
site_number <- paste0("0",info[counter,2]) #input for model data import
rmarkdown::render(paste0("Working_Dashboard_2019.Rmd"), "pdf_document", output_dir = output.dir, output_file = paste0(riv.seg, ".pdf"),
params = list(token = token, riv.seg = riv.seg))
# LOADING DATA ------------------------------------------------------------
data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data1 <- water_year_trim(data1)
data2 <- water_year_trim(data2)
metrics1 <- metrics_calc_all(data1) #calculate metrics into a matrix
metrics2 <- metrics_calc_all(data2)
all_metrics <- metrics_compare(metrics1, metrics2, riv.seg)
# table.metrics1 <- data.frame(riv.seg,metrics1[1,1],metrics1[1,67],metrics1[1,61],metrics1[1,59]) #create row to add to overall dataframe
# table.metrics2 <- data.frame(riv.seg,metrics2[1,1],metrics2[1,67],metrics2[1,61],metrics2[1,59]) #create row to add to overall dataframe
# colnames(table.metrics1) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
# colnames(table.metrics2) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
base.table <- rbind(base.table, metrics1, stringsAsFactors = FALSE)
climatechange.table <- rbind(climatechange.table, metrics2, stringsAsFactors = FALSE)
counter <- counter + 1
}
write.csv(base.table, file = paste0(output.dir, '//Base_2018_Metrics.csv'))
write.csv(climatechange.table, file = paste0(output.dir, '//Climate_Change_Metrics.csv'))
}
automated_dashboard(mod.phase1,mod.scenario1,mod.phase2,mod.scenario2,start.date,end.date,github_link,site_url,site.or.server)
automated_dashboard <- function(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url, site.or.server) {
cbp6_link = paste0(github_link, "/cbp6/code");
setwd(cbp6_link)
dir.create('dashboard comparisons')
output.dir <- paste0(cbp6_link, '\\dashboard comparisons')
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste0(github_link, "/auth.private"));
#load rest username and password, contained in auth.private file
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
info <- read.csv(paste0(cbp6_link, "/data.csv"))
base.table <- data.frame()
climatechange.table <- data.frame()
counter <- 1
while (counter <= 10) { #change to number of rows on full csv
riv.seg <- as.character(info[counter,1]) #input for model data import
site_number <- paste0("0",info[counter,2]) #input for model data import
rmarkdown::render(paste0("Working_Dashboard_2019.Rmd"), "pdf_document", output_dir = output.dir, output_file = paste0(riv.seg, ".pdf"),
params = list(token = token, riv.seg = riv.seg))
# LOADING DATA ------------------------------------------------------------
data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
data1 <- water_year_trim(data1)
data2 <- water_year_trim(data2)
metrics1 <- metrics_calc_all(data1) #calculate metrics into a matrix
rownames(metrics1) <- (riv.seg)
metrics2 <- metrics_calc_all(data2)
rownames(metrics2) <- (riv.seg)
all_metrics <- metrics_compare(metrics1, metrics2, riv.seg)
# table.metrics1 <- data.frame(riv.seg,metrics1[1,1],metrics1[1,67],metrics1[1,61],metrics1[1,59]) #create row to add to overall dataframe
# table.metrics2 <- data.frame(riv.seg,metrics2[1,1],metrics2[1,67],metrics2[1,61],metrics2[1,59]) #create row to add to overall dataframe
# colnames(table.metrics1) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
# colnames(table.metrics2) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
base.table <- rbind(base.table, metrics1, stringsAsFactors = FALSE)
climatechange.table <- rbind(climatechange.table, metrics2, stringsAsFactors = FALSE)
counter <- counter + 1
}
write.csv(base.table, file = paste0(output.dir, '//Base_2018_Metrics.csv'))
write.csv(climatechange.table, file = paste0(output.dir, '//Climate_Change_Metrics.csv'))
}
automated_dashboard(mod.phase1,mod.scenario1,mod.phase2,mod.scenario2,start.date,end.date,github_link,site_url,site.or.server)
warnings()
