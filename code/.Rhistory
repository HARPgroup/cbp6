'Mar. Mean Flow', 'Apr. Mean Flow', 'May Mean Flow',
'June Mean Flow', 'July Mean Flow', 'Aug. Mean Flow',
'Sep. Mean Flow', 'Oct. Mean Flow', 'Nov. Mean Flow',
'Dec. Mean Flow', 'Min. 1-Day Low Flow', 'Med. 1-Day Low Flow',
'Min. 3-Day Low Flow', 'Med. 3-Day Low Flow', 'Min. 7-Day Low Flow',
'Med. 7-Day Low Flow', 'Min. 30-Day Low Flow', 'Med. 30-Day Low Flow',
'Min. 90-Day Low Flow', 'Med. 90-Day Low Flow', 'x7q10',
'1pct Non-Exceedance', '5pct Non-Exceedance',
'50pct Non-Exceedance', '95pct Non-Exceedance', '99pct Non-Exceedance',
'Sep. 10pct Non-Exceedance', 'Mean Baseflow', 'Jan. High Flow',
'Feb. High Flow', 'Mar. High Flow', 'Apr. High Flow',
'May High Flow', 'June High Flow', 'July High Flow',
'Aug. High Flow', 'Sep. High Flow', 'Oct. High Flow',
'Nov. High Flow', 'Dec. High Flow', 'Max. 1-Day High Flow',
'Med. 1-Day High Flow', 'Max. 3-Day High Flow', 'Med. 3-Day High Flow',
'Max. 7-Day High Flow', 'Med. 7-Day High Flow', 'Max. 30-Day High Flow',
'Med. 30-Day High Flow', 'Max. 90-Day High Flow', 'Med. 90-Day High Flow',
"Drought Year Mean", "Contrib. Drainage Area")
metrics.names[36]
github_link = '~'
site = "http://deq2.bse.vt.edu/d.dh"
cbp6_link = paste0(github_link, "/cbp6/code")
source(paste0(cbp6_link,"/cbp6_functions.R"))
github_link = 'C:\\Users\\danie\\Documents\\HARP\\GitHub'
site = "http://deq2.bse.vt.edu/d.dh"
cbp6_link = paste0(github_link, "/cbp6/code")
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token1 <- rest_token(site, token1, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
token <- token1
cbp6_link = paste0(github_link, "/cbp6/code")
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
info <- read.csv(paste0(cbp6_link, "/data.csv"))
all.riv.segs <- as.vector(info$riv.seg)
num.segs <- as.numeric(length(all.riv.segs))
seg.names <- all.riv.segs
metrics.names <- 'x7q10'
num.metrics <- length(metrics.names)
# CREATES EMPTY DATA FRAME WITH DIMENSIONS OF ALL METRICS BY NUM.SEGS ------------
all.errors.all.segments <- data.frame(matrix(NA, nrow = num.segs, ncol = num.metrics))
colnames(all.errors.all.segments) <- metrics.names
rownames(all.errors.all.segments) <- seg.names
# POPULATES DATA FRAME WITH ALL_METRICS PERCENT ERROR DATA -----------------------
all.errors.line.no <- 1
for (i in start.num:num.segs) {
RivSeg <- all.riv.segs[i]
print(paste('Downloading data for segment', i, 'of', num.segs))
# 35: 7Q10
alfinfo <- list(
varkey = "7q10",
featureid = as.integer(as.character(model$pid)),
entity_type = "dh_properties"
)
alfprop <- getProperty(alfinfo, site, alfprop)
all.metrics[1,1] <- alfprop$propvalue
all.errors.all.segments[all.errors.line.no,] <- all.metrics[1,1:num.metrics]
#Normalizing data: dividing all metrics by the contributing drainage area of the river segment
all.errors.all.segments[all.errors.line.no,-num.metrics] <- all.errors.all.segments[all.errors.line.no,-num.metrics]/all.errors.all.segments[all.errors.line.no,num.metrics]
all.errors.line.no <- all.errors.line.no + 1
}
start.num <- 1
for (i in start.num:num.segs) {
RivSeg <- all.riv.segs[i]
print(paste('Downloading data for segment', i, 'of', num.segs))
# 35: 7Q10
alfinfo <- list(
varkey = "7q10",
featureid = as.integer(as.character(model$pid)),
entity_type = "dh_properties"
)
alfprop <- getProperty(alfinfo, site, alfprop)
all.metrics[1,1] <- alfprop$propvalue
all.errors.all.segments[all.errors.line.no,] <- all.metrics[1,1:num.metrics]
#Normalizing data: dividing all metrics by the contributing drainage area of the river segment
all.errors.all.segments[all.errors.line.no,-num.metrics] <- all.errors.all.segments[all.errors.line.no,-num.metrics]/all.errors.all.segments[all.errors.line.no,num.metrics]
all.errors.line.no <- all.errors.line.no + 1
}
for (i in start.num:num.segs) {
RivSeg <- all.riv.segs[i]
print(paste('Downloading data for segment', i, 'of', num.segs))
# GETTING MODEL DATA FROM VA HYDRO
hydrocode = paste("vahydrosw_wshed_",RivSeg,sep="");
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
hydroid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
print(paste("Retrieved hydroid",hydroid,"for", fname,RivSeg, sep=' '));
# get the p5.3.2, scenario  model segment attached to this river feature
inputs <- list(
varkey = "om_model_element",
featureid = hydroid,
entity_type = "dh_feature",
propcode = mod.scenario
)
token = token
model <- getProperty(inputs, site, model)
all.metrics <- data.frame(matrix(NA, nrow = 1, ncol = num.metrics))
# Getting the contributing drainage area feature
areainfo <- list(
varkey = "wshed_drainage_area_sqmi",
featureid = as.integer(as.character(hydroid)),
entity_type = "dh_feature"
)
contrib.drain.area <- getProperty(areainfo, site, contrib.drain.area)
all.metrics[1,num.metrics] <- contrib.drain.area$propvalue
all.metrics[1,num.metrics] <- all.metrics[1,num.metrics]
# GETTING MODEL METRICS FROM VA HYDRO
# 35: 7Q10
alfinfo <- list(
varkey = "7q10",
featureid = as.integer(as.character(model$pid)),
entity_type = "dh_properties"
)
alfprop <- getProperty(alfinfo, site, alfprop)
all.metrics[1,1] <- alfprop$propvalue
all.errors.all.segments[all.errors.line.no,] <- all.metrics[1,1:num.metrics]
#Normalizing data: dividing all metrics by the contributing drainage area of the river segment
all.errors.all.segments[all.errors.line.no,-num.metrics] <- all.errors.all.segments[all.errors.line.no,-num.metrics]/all.errors.all.segments[all.errors.line.no,num.metrics]
all.errors.line.no <- all.errors.line.no + 1
}
mod.scenario <- 'CFBASE30Y20180615'
for (i in start.num:num.segs) {
RivSeg <- all.riv.segs[i]
print(paste('Downloading data for segment', i, 'of', num.segs))
# GETTING MODEL DATA FROM VA HYDRO
hydrocode = paste("vahydrosw_wshed_",RivSeg,sep="");
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
hydroid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
print(paste("Retrieved hydroid",hydroid,"for", fname,RivSeg, sep=' '));
# get the p5.3.2, scenario  model segment attached to this river feature
inputs <- list(
varkey = "om_model_element",
featureid = hydroid,
entity_type = "dh_feature",
propcode = mod.scenario
)
token = token
model <- getProperty(inputs, site, model)
all.metrics <- data.frame(matrix(NA, nrow = 1, ncol = num.metrics))
# Getting the contributing drainage area feature
areainfo <- list(
varkey = "wshed_drainage_area_sqmi",
featureid = as.integer(as.character(hydroid)),
entity_type = "dh_feature"
)
contrib.drain.area <- getProperty(areainfo, site, contrib.drain.area)
all.metrics[1,num.metrics] <- contrib.drain.area$propvalue
all.metrics[1,num.metrics] <- all.metrics[1,num.metrics]
# GETTING MODEL METRICS FROM VA HYDRO
# 35: 7Q10
alfinfo <- list(
varkey = "7q10",
featureid = as.integer(as.character(model$pid)),
entity_type = "dh_properties"
)
alfprop <- getProperty(alfinfo, site, alfprop)
all.metrics[1,1] <- alfprop$propvalue
all.errors.all.segments[all.errors.line.no,] <- all.metrics[1,1:num.metrics]
#Normalizing data: dividing all metrics by the contributing drainage area of the river segment
all.errors.all.segments[all.errors.line.no,-num.metrics] <- all.errors.all.segments[all.errors.line.no,-num.metrics]/all.errors.all.segments[all.errors.line.no,num.metrics]
all.errors.line.no <- all.errors.line.no + 1
}
Metrics <- all.errors.all.segments[,-num.metrics]
Metrics
Metrics <- all.errors.all.segments[,]
Metrics
which(is.numeric(Metrics) == TRUE)
metrics.names[24]
seg.names[24]
seg.names[27]
github_link = 'C:\\Users\\danie\\Documents\\HARP\\GitHub'
site = "http://deq2.bse.vt.edu/d.dh"
cbp6_link = paste0(github_link, "/cbp6/code")
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token1 <- rest_token(site, token1, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
token <- token1
cbp6_link = paste0(github_link, "/cbp6/code")
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
mod.scenario <- 'CFBASE30Y20180615'
info <- read.csv(paste0(cbp6_link, "/data.csv"))
all.riv.segs <- as.vector(info$riv.seg)
num.segs <- as.numeric(length(all.riv.segs))
seg.names <- all.riv.segs
metrics.names <- 'x7q10'
num.metrics <- length(metrics.names)
# CREATES EMPTY DATA FRAME WITH DIMENSIONS OF ALL METRICS BY NUM.SEGS ------------
all.errors.all.segments <- data.frame(matrix(NA, nrow = num.segs, ncol = num.metrics))
colnames(all.errors.all.segments) <- metrics.names
rownames(all.errors.all.segments) <- seg.names
# POPULATES DATA FRAME WITH ALL_METRICS PERCENT ERROR DATA -----------------------
all.errors.line.no <- 1
start.num <- 1
for (i in start.num:num.segs) {
RivSeg <- all.riv.segs[i]
print(paste('Downloading data for segment', i, 'of', num.segs))
# GETTING MODEL DATA FROM VA HYDRO
hydrocode = paste("vahydrosw_wshed_",RivSeg,sep="");
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
hydroid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
print(paste("Retrieved hydroid",hydroid,"for", fname,RivSeg, sep=' '));
# get the p5.3.2, scenario  model segment attached to this river feature
inputs <- list(
varkey = "om_model_element",
featureid = hydroid,
entity_type = "dh_feature",
propcode = mod.scenario
)
token = token
model <- getProperty(inputs, site, model)
all.metrics <- data.frame(matrix(NA, nrow = 1, ncol = num.metrics))
# Getting the contributing drainage area feature
areainfo <- list(
varkey = "wshed_drainage_area_sqmi",
featureid = as.integer(as.character(hydroid)),
entity_type = "dh_feature"
)
contrib.drain.area <- getProperty(areainfo, site, contrib.drain.area)
all.metrics[1,num.metrics] <- contrib.drain.area$propvalue
all.metrics[1,num.metrics] <- all.metrics[1,num.metrics]
# GETTING MODEL METRICS FROM VA HYDRO
# 35: 7Q10
alfinfo <- list(
varkey = "7q10",
featureid = as.integer(as.character(model$pid)),
entity_type = "dh_properties"
)
alfprop <- getProperty(alfinfo, site, alfprop)
all.metrics[1,1] <- alfprop$propvalue
all.errors.all.segments[all.errors.line.no,] <- all.metrics[1,1:num.metrics]
#Normalizing data: dividing all metrics by the contributing drainage area of the river segment
all.errors.all.segments[all.errors.line.no,-num.metrics] <- all.errors.all.segments[all.errors.line.no,-num.metrics]/all.errors.all.segments[all.errors.line.no,num.metrics]
all.errors.line.no <- all.errors.line.no + 1
}
Metrics <- all.errors.all.segments[,]
Metrics
mod.scenario <- 'CBASE1808L55CY55R45P50R45P50Y'
info <- read.csv(paste0(cbp6_link, "/data.csv"))
all.riv.segs <- as.vector(info$riv.seg)
num.segs <- as.numeric(length(all.riv.segs))
seg.names <- all.riv.segs
metrics.names <- 'x7q10'
num.metrics <- length(metrics.names)
# CREATES EMPTY DATA FRAME WITH DIMENSIONS OF ALL METRICS BY NUM.SEGS ------------
all.errors.all.segments <- data.frame(matrix(NA, nrow = num.segs, ncol = num.metrics))
colnames(all.errors.all.segments) <- metrics.names
rownames(all.errors.all.segments) <- seg.names
# POPULATES DATA FRAME WITH ALL_METRICS PERCENT ERROR DATA -----------------------
all.errors.line.no <- 1
start.num <- 1
for (i in start.num:num.segs) {
RivSeg <- all.riv.segs[i]
print(paste('Downloading data for segment', i, 'of', num.segs))
# GETTING MODEL DATA FROM VA HYDRO
hydrocode = paste("vahydrosw_wshed_",RivSeg,sep="");
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
hydroid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
print(paste("Retrieved hydroid",hydroid,"for", fname,RivSeg, sep=' '));
# get the p5.3.2, scenario  model segment attached to this river feature
inputs <- list(
varkey = "om_model_element",
featureid = hydroid,
entity_type = "dh_feature",
propcode = mod.scenario
)
token = token
model <- getProperty(inputs, site, model)
all.metrics <- data.frame(matrix(NA, nrow = 1, ncol = num.metrics))
# Getting the contributing drainage area feature
areainfo <- list(
varkey = "wshed_drainage_area_sqmi",
featureid = as.integer(as.character(hydroid)),
entity_type = "dh_feature"
)
contrib.drain.area <- getProperty(areainfo, site, contrib.drain.area)
all.metrics[1,num.metrics] <- contrib.drain.area$propvalue
all.metrics[1,num.metrics] <- all.metrics[1,num.metrics]
# GETTING MODEL METRICS FROM VA HYDRO
# 35: 7Q10
alfinfo <- list(
varkey = "7q10",
featureid = as.integer(as.character(model$pid)),
entity_type = "dh_properties"
)
alfprop <- getProperty(alfinfo, site, alfprop)
all.metrics[1,1] <- alfprop$propvalue
all.errors.all.segments[all.errors.line.no,] <- all.metrics[1,1:num.metrics]
#Normalizing data: dividing all metrics by the contributing drainage area of the river segment
all.errors.all.segments[all.errors.line.no,-num.metrics] <- all.errors.all.segments[all.errors.line.no,-num.metrics]/all.errors.all.segments[all.errors.line.no,num.metrics]
all.errors.line.no <- all.errors.line.no + 1
}
Metrics <- all.errors.all.segments[,]
Metrics
seg.names[25]
which(Metrics == NaN)
which(Metrics == 'NaN')
seg.names(probs)
seg.names[probs]
probs <- which(Metrics == 'NaN')
seg.names[probs]
riv.seg <- 'PM7_4620_4580'
mod.phase <- 'CBASE1808L55CY55R45P50R45P50Y'
mod.phase <- 'p6/p6_gb604'
mod.scenario <- 'CBASE1808L55CY55R45P50R45P50Y'
mod.phase <- 'p6/p6_gb604/tmp'
start.data <- '1984-01-01'
start.date <- '1984-01-01'
end.date <- '2014-12-31'
model_import_data_cfs <- function(riv.seg, mod.phase, mod.scenario, start.date, end.date) {
# Downloading and exporting hourly model data
model_hourly <- read.csv(paste0("http://deq2.bse.vt.edu/", mod.phase, "/wdm/river/", mod.scenario, "/stream/",
riv.seg, "_0111.csv"), header = FALSE, sep = ",", stringsAsFactors = FALSE);
RivSegStr1 <- strsplit(riv.seg, "\\+")
RivSegStr1 <- RivSegStr1[[1]]
num.segs1 <- length(RivSegStr1)
model_days1 <- length(seq(as.Date(start.date):as.Date(end.date)))
# Converting hourly to daily data and exporting daily data
model_hourly <- model_hourly[-1,]
model_hourly$V1 <- trimws(model_hourly$V1, which = "both")
colnames(model_hourly) <- c("year","month","day","hour","ovol")
model_hourly$date <- as.Date(paste0(model_hourly$year,"-",model_hourly$month,"-",model_hourly$day))
model_daily <- aggregate(model_hourly$ovol, list(model_hourly$date), FUN = sum)
colnames(model_daily) <- c("date","flow")
start.line <- as.numeric(which(model_daily$date == start.date))
end.line <- as.numeric(which(model_daily$date == end.date))
model_daily <- model_daily[start.line:end.line,]
model_daily$flow <- signif(model_daily$flow * 0.504167, digits=3) # conversion from acre-feet to cfs
return(model_daily)
}
model_import_data_cfs(riv.seg,mod.phase,mod.scenario,start.date,end.date)
mod.phase <- 'p6/p6_gb604'
model_import_data_cfs(riv.seg,mod.phase,mod.scenario,start.date,end.date)
paste0("http://deq2.bse.vt.edu/", mod.phase, "/wdm/river/", mod.scenario, "/stream/",
riv.seg, "_0111.csv"), header = FALSE, sep = ",", stringsAsFactors = FALSE)
paste0("http://deq2.bse.vt.edu/", mod.phase, "/wdm/river/", mod.scenario, "/stream/",
riv.seg, "_0111.csv")
mod.phase <- 'p6/p6_gb604/tmp'
paste0("http://deq2.bse.vt.edu/", mod.phase, "/wdm/river/", mod.scenario, "/stream/",
riv.seg, "_0111.csv")
paste0("http://deq2.bse.vt.edu/", mod.phase, "/wdm/river/", mod.scenario, "/stream/",
riv.seg, "_0111.csv")
mod.phase <- 'p6/p6_gb604/out'
model_import_data_cfs(riv.seg,mod.phase,mod.scenario,start.date,end.date)
model_import_data_cfs <- function(riv.seg, mod.phase, mod.scenario, start.date, end.date) {
# Downloading and exporting hourly model data
model_hourly <- read.csv(paste0("http://deq2.bse.vt.edu/", mod.phase, "/river/", mod.scenario, "/stream/",
riv.seg, "_0111.csv"), header = FALSE, sep = ",", stringsAsFactors = FALSE);
RivSegStr1 <- strsplit(riv.seg, "\\+")
RivSegStr1 <- RivSegStr1[[1]]
num.segs1 <- length(RivSegStr1)
model_days1 <- length(seq(as.Date(start.date):as.Date(end.date)))
# Converting hourly to daily data and exporting daily data
model_hourly <- model_hourly[-1,]
model_hourly$V1 <- trimws(model_hourly$V1, which = "both")
colnames(model_hourly) <- c("year","month","day","hour","ovol")
model_hourly$date <- as.Date(paste0(model_hourly$year,"-",model_hourly$month,"-",model_hourly$day))
model_daily <- aggregate(model_hourly$ovol, list(model_hourly$date), FUN = sum)
colnames(model_daily) <- c("date","flow")
start.line <- as.numeric(which(model_daily$date == start.date))
end.line <- as.numeric(which(model_daily$date == end.date))
model_daily <- model_daily[start.line:end.line,]
model_daily$flow <- signif(model_daily$flow * 0.504167, digits=3) # conversion from acre-feet to cfs
return(model_daily)
}
model_import_data_cfs(riv.seg,mod.phase,mod.scenario,start.date,end.date)
end.date <- '2000-12-31'
model_import_data_cfs(riv.seg,mod.phase,mod.scenario,start.date,end.date)
data <- model_import_data_cfs(riv.seg,mod.phase,mod.scenario,start.date,end.date)
# Creating Data Frame with calculated metrics
metrics_calc_all <- function(data) {
overall.mean <- overall_mean_flow(data)
jan.low.flow <- monthly_min(data, num.month = 1)
feb.low.flow <- monthly_min(data, num.month = 2)
mar.low.flow <- monthly_min(data, num.month = 3)
apr.low.flow <- monthly_min(data, num.month = 4)
may.low.flow <- monthly_min(data, num.month = 5)
jun.low.flow <- monthly_min(data, num.month = 6)
jul.low.flow <- monthly_min(data, num.month = 7)
aug.low.flow <- monthly_min(data, num.month = 8)
sep.low.flow <- monthly_min(data, num.month = 9)
oct.low.flow <- monthly_min(data, num.month = 10)
nov.low.flow <- monthly_min(data, num.month = 11)
dec.low.flow <- monthly_min(data, num.month = 12)
jan.mean.flow <- monthly_mean(data, num.month = 1)
feb.mean.flow <- monthly_mean(data, num.month = 2)
mar.mean.flow <- monthly_mean(data, num.month = 3)
apr.mean.flow <- monthly_mean(data, num.month = 4)
may.mean.flow <- monthly_mean(data, num.month = 5)
jun.mean.flow <- monthly_mean(data, num.month = 6)
jul.mean.flow <- monthly_mean(data, num.month = 7)
aug.mean.flow <- monthly_mean(data, num.month = 8)
sep.mean.flow <- monthly_mean(data, num.month = 9)
oct.mean.flow <- monthly_mean(data, num.month = 10)
nov.mean.flow <- monthly_mean(data, num.month = 11)
dec.mean.flow <- monthly_mean(data, num.month = 12)
jan.high.flow <- monthly_max(data, num.month = 1)
feb.high.flow <- monthly_max(data, num.month = 2)
mar.high.flow <- monthly_max(data, num.month = 3)
apr.high.flow <- monthly_max(data, num.month = 4)
may.high.flow <- monthly_max(data, num.month = 5)
jun.high.flow <- monthly_max(data, num.month = 6)
jul.high.flow <- monthly_max(data, num.month = 7)
aug.high.flow <- monthly_max(data, num.month = 8)
sep.high.flow <- monthly_max(data, num.month = 9)
oct.high.flow <- monthly_max(data, num.month = 10)
nov.high.flow <- monthly_max(data, num.month = 11)
dec.high.flow <- monthly_max(data, num.month = 12)
one.day.min <- num_day_min(data, num.day = 1, min_or_med = "min")
three.day.min <- num_day_min(data, num.day = 3, min_or_med = "min")
seven.day.min <- num_day_min(data, num.day = 7, min_or_med = "min")
thirty.day.min <- num_day_min(data, num.day = 30, min_or_med = "min")
ninety.day.min <- num_day_min(data, num.day = 90, min_or_med = "min")
one.day.med.min <- num_day_min(data, num.day = 1, min_or_med = "med")
three.day.med.min <- num_day_min(data, num.day = 3, min_or_med = "med")
seven.day.med.min <- num_day_min(data, num.day = 7, min_or_med = "med")
thirty.day.med.min <- num_day_min(data, num.day = 30, min_or_med = "med")
ninety.day.med.min <- num_day_min(data, num.day = 90, min_or_med = "med")
one.day.max <- num_day_max(data, num.day = 1, max_or_med = "max")
three.day.max <- num_day_max(data, num.day = 3, max_or_med = "max")
seven.day.max <- num_day_max(data, num.day = 7, max_or_med = "max")
thirty.day.max <- num_day_max(data, num.day = 30, max_or_med = "max")
ninety.day.max <- num_day_max(data, num.day = 90, max_or_med = "max")
one.day.med.max <- num_day_max(data, num.day = 1, max_or_med = "med")
three.day.med.max <- num_day_max(data, num.day = 3, max_or_med = "med")
seven.day.med.max <- num_day_max(data, num.day = 7, max_or_med = "med")
thirty.day.med.max <- num_day_max(data, num.day = 30, max_or_med = "med")
ninety.day.med.max <- num_day_max(data, num.day = 90, max_or_med = "med")
lowest.yearly.mean <- low_yearly_mean(data)
sevenQ.ten <- seven_q_ten(data)
drought.record <- drought_of_record(data)
sept.10.percent <- sept_10_flow(data)
flow.exceedance.1 <- flow_exceedance(data, prob = 0.01)
flow.exceedance.5 <- flow_exceedance(data, prob = 0.05)
flow.exceedance.50 <- flow_exceedance(data, prob = 0.5)
flow.exceedance.95 <- flow_exceedance(data, prob = 0.95)
flow.exceedance.99 <- flow_exceedance(data, prob = 0.99)
avg.baseflow <- average_baseflow(data)
all_metrics <- data.frame(overall.mean, jan.low.flow, feb.low.flow, mar.low.flow, apr.low.flow, may.low.flow,jun.low.flow, jul.low.flow, aug.low.flow, sep.low.flow, oct.low.flow, nov.low.flow, dec.low.flow, jan.mean.flow, feb.mean.flow, mar.mean.flow, apr.mean.flow, may.mean.flow, jun.mean.flow, jul.mean.flow, aug.mean.flow, sep.mean.flow, oct.mean.flow, nov.mean.flow, dec.mean.flow, jan.high.flow, feb.high.flow, mar.high.flow, apr.high.flow, may.high.flow, jun.high.flow, jul.high.flow, aug.high.flow, sep.high.flow, oct.high.flow, nov.high.flow, dec.high.flow, one.day.min, three.day.min, seven.day.min, thirty.day.min, ninety.day.min, one.day.med.min, three.day.med.min, seven.day.med.min, thirty.day.med.min, ninety.day.med.min, one.day.max, three.day.max, seven.day.max, thirty.day.max, ninety.day.max, one.day.med.max, three.day.med.max, seven.day.med.max, thirty.day.med.max, ninety.day.med.max, lowest.yearly.mean, sevenQ.ten, drought.record, sept.10.percent, flow.exceedance.1, flow.exceedance.5, flow.exceedance.50, flow.exceedance.95, flow.exceedance.99, avg.baseflow)
rownames(all_metrics) <- 'analysis'
return(all_metrics)
}
metrics_calc_all(data)
github_link <- 'C:\\Users\\danie\\Documents\\HARP\\GitHub'
cbp6_link = paste0(github_link, "/cbp6/code");
setwd(cbp6_link)
dir.create(paste0('/opt/model/p6/p6_gb604/out/dashboards/', mod.scenario1, '.vs.', mod.scenario2))
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
metrics_calc_all(data)
library(lubridate)
metrics_calc_all(data)
library(zoo)
metrics_calc_all(data)
library(IHA)
metrics_calc_all(data)
library(lfstat)
metrics_calc_all(data)
library(PearsonDS)
metrics_calc_all(data)
compare_this <- metrics_calc_all(data)
View(compare_this)
riv.seg
compare <- t(compare_this)
compare
View(compare)
water_year_trim(data)
data <- water_year_trim(data)
compare_this <- t(metrics_calc_all(data))
compare_this
View(compare_this)
