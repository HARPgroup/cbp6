# does not exist locally
if (finfo$compressed == 1) {
print(paste("Downloading Compressed Run File ", filename));
download.file(filename,'tempfile',mode="wb", method = "libcurl");
filename <-  unzip ('tempfile');
}
}
dat = try(read.table( filename, header = TRUE, sep = ",")) ;
if (class(dat)=='try-error') {
# what to do if file empty
print(paste("Error: empty file ", filename))
return (FALSE);
} else {
#dat<-read.table(filename, header = TRUE, sep = ",")   #  reads the csv-formatted data from the url
print(paste("Data obtained, found ", length(dat[,1]), " lines - formatting for IHA analysis"))
datv<-as.vector(dat)  # stores the data as a vector
datv$timestamp <- as.POSIXct(datv$timestamp,origin="1970-01-01")
f3 <- zoo(datv, order.by = datv$timestamp)
}
unlink('tempfile')
if(outaszoo){
return(f3)
}else{
return(datv)
}
}
fn_storeprop_vahydro1 = function(site = "http://deq2.bse.vt.edu"){
# NOT FINISHED - JUST PASTED CODE
url <- paste(site,"om/remote/setModelData.php?hash=", sep='/');
print (paste("Setting 7Q10 for element ", id, " run id ", rid, " to ", x7q10 , sep = "") )
# building the correct url
ins_url <- paste(url, hash, "&username=", username, "&elementid=", id, "&runid=", rid, "&dataname=7q10&reporting_frequency=single&dataval=", x7q10, "&starttime=1984-10-01&endtime=2005-09-30&temporal_res=water_year", sep = "")
#shell.exec(alf_url)  # opening the webpage
print(ins_url);
readLines(ins_url)
}
dat <- fn_get_runfile(elid, runid, site = omsite,  cached = FALSE);
uninstall.packages('hydroTSM')
remove.packages('hydroTSM')
install.packages('hydroTSM')
library(pander);
library(httr);
library(hydroTSM);
save_directory <- "/var/www/html/files/fe/plots"
#----------------------------------------------
site <- "http://deq2.bse.vt.edu/d.dh"    #Specify the site of interest, either d.bet OR d.dh
#----------------------------------------------
# Load Libraries
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
hydro_tools <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\hydro-tools"
source(paste(github_link,'config.local.private',sep='/'));
source(paste(hydro_tools,"VAHydro-2.0/rest_functions.R", sep = "/"));
source(paste(hydro_tools,"VAHydro-1.0/fn_vahydro-1.0.R", sep = "/"));
source(paste(hydro_tools,"LowFlow/fn_iha.R", sep = "/"));
#retrieve rest token - DISABLED
#fxn_locations <-  '/usr/local/home/git/r-dh-ecohydro/ELFGEN';
#source(paste(fxn_locations,"elf_rest_token.R", sep = "/"));
#elf_rest_token (site, token)
# to run in knit'r, need to preload token
#token = 'W-THcwwvstkINd9NIeEMrmNRls-8kVs16mMEcN_-jOA';
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
hydrocode = "vahydrosw_wshed_JU3_7490_7400";
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
# Ex: flows <- fn_get_rundata(207885, 402);
#     fn_iha_7q10(flows);
# Get data frame for stashing multirun data
stash <- data.frame();
mostash <- data.frame();
tsstash = FALSE;
featureid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = featureid,
entity_type = "dh_feature"
)
da <- getProperty(inputs, site, model)
inputs <- list(
varkey = "om_model_element",
featureid = featureid,
entity_type = "dh_feature",
propcode = "vahydro-1.0"
)
model <- getProperty(inputs, site, model)
mid = as.numeric(as.character(model[1,]$pid))
inputs <- list(
varkey = "om_element_connection",
featureid = mid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
# Manual elid
elid = as.numeric(as.character(prop[1,]$propvalue))
# Analsyis config
#runids = c(20021,20023);
#runids = c(20051,20054);
runid = 105
wshed_summary_tbl = data.frame(
"Run ID" = character(),
"Segment Name (D. Area)" = character(),
"7Q10/ALF/LF-90" = character(),
"WD (mean/max)" = character(),
stringsAsFactors = FALSE) ;
#pander(odata);
#pander(odata);
omsite = site <- "http://deq2.bse.vt.edu"
dat <- fn_get_runfile(elid, runid, site = omsite,  cached = FALSE);
install.packages(c("callr", "curl", "devtools", "digest", "DT", "ellipsis", "gstat", "httpuv", "knitr", "pkgconfig", "raster", "sf", "tidyr", "tinytex", "TTR"))
library(pander);
library(httr);
library(hydroTSM);
save_directory <- "/var/www/html/files/fe/plots"
#----------------------------------------------
site <- "http://deq2.bse.vt.edu/d.dh"    #Specify the site of interest, either d.bet OR d.dh
#----------------------------------------------
# Load Libraries
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
hydro_tools <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\hydro-tools"
source(paste(github_link,'config.local.private',sep='/'));
source(paste(hydro_tools,"VAHydro-2.0/rest_functions.R", sep = "/"));
source(paste(hydro_tools,"VAHydro-1.0/fn_vahydro-1.0.R", sep = "/"));
source(paste(hydro_tools,"LowFlow/fn_iha.R", sep = "/"));
#retrieve rest token - DISABLED
#fxn_locations <-  '/usr/local/home/git/r-dh-ecohydro/ELFGEN';
#source(paste(fxn_locations,"elf_rest_token.R", sep = "/"));
#elf_rest_token (site, token)
# to run in knit'r, need to preload token
#token = 'W-THcwwvstkINd9NIeEMrmNRls-8kVs16mMEcN_-jOA';
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
hydrocode = "vahydrosw_wshed_JU3_7490_7400";
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
# Ex: flows <- fn_get_rundata(207885, 402);
#     fn_iha_7q10(flows);
# Get data frame for stashing multirun data
stash <- data.frame();
mostash <- data.frame();
tsstash = FALSE;
featureid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = featureid,
entity_type = "dh_feature"
)
da <- getProperty(inputs, site, model)
inputs <- list(
varkey = "om_model_element",
featureid = featureid,
entity_type = "dh_feature",
propcode = "vahydro-1.0"
)
model <- getProperty(inputs, site, model)
mid = as.numeric(as.character(model[1,]$pid))
inputs <- list(
varkey = "om_element_connection",
featureid = mid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
# Manual elid
elid = as.numeric(as.character(prop[1,]$propvalue))
# Analsyis config
#runids = c(20021,20023);
#runids = c(20051,20054);
runid = 105
wshed_summary_tbl = data.frame(
"Run ID" = character(),
"Segment Name (D. Area)" = character(),
"7Q10/ALF/LF-90" = character(),
"WD (mean/max)" = character(),
stringsAsFactors = FALSE) ;
#pander(odata);
#pander(odata);
omsite = site <- "http://deq2.bse.vt.edu"
dat <- fn_get_runfile(elid, runid, site = omsite,  cached = FALSE);
library(pander);
library(httr);
library(hydroTSM);
save_directory <- "/var/www/html/files/fe/plots"
#----------------------------------------------
site <- "http://deq2.bse.vt.edu/d.dh"    #Specify the site of interest, either d.bet OR d.dh
#----------------------------------------------
# Load Libraries
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
hydro_tools <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\hydro-tools"
source(paste(github_link,'config.local.private',sep='/'));
source(paste(hydro_tools,"VAHydro-2.0/rest_functions.R", sep = "/"));
source(paste(hydro_tools,"VAHydro-1.0/fn_vahydro-1.0.R", sep = "/"));
source(paste(hydro_tools,"LowFlow/fn_iha.R", sep = "/"));
#retrieve rest token - DISABLED
#fxn_locations <-  '/usr/local/home/git/r-dh-ecohydro/ELFGEN';
#source(paste(fxn_locations,"elf_rest_token.R", sep = "/"));
#elf_rest_token (site, token)
# to run in knit'r, need to preload token
#token = 'W-THcwwvstkINd9NIeEMrmNRls-8kVs16mMEcN_-jOA';
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
hydrocode = "vahydrosw_wshed_JU3_7490_7400";
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
# Ex: flows <- fn_get_rundata(207885, 402);
#     fn_iha_7q10(flows);
# Get data frame for stashing multirun data
stash <- data.frame();
mostash <- data.frame();
tsstash = FALSE;
featureid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = featureid,
entity_type = "dh_feature"
)
da <- getProperty(inputs, site, model)
inputs <- list(
varkey = "om_model_element",
featureid = featureid,
entity_type = "dh_feature",
propcode = "vahydro-1.0"
)
model <- getProperty(inputs, site, model)
mid = as.numeric(as.character(model[1,]$pid))
inputs <- list(
varkey = "om_element_connection",
featureid = mid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
# Manual elid
elid = as.numeric(as.character(prop[1,]$propvalue))
# Analsyis config
#runids = c(20021,20023);
#runids = c(20051,20054);
runid = 106
wshed_summary_tbl = data.frame(
"Run ID" = character(),
"Segment Name (D. Area)" = character(),
"7Q10/ALF/LF-90" = character(),
"WD (mean/max)" = character(),
stringsAsFactors = FALSE) ;
#pander(odata);
#pander(odata);
library(pander);
library(httr);
library(hydroTSM);
save_directory <- "/var/www/html/files/fe/plots"
#----------------------------------------------
site <- "http://deq2.bse.vt.edu/d.dh"    #Specify the site of interest, either d.bet OR d.dh
#----------------------------------------------
# Load Libraries
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
hydro_tools <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\hydro-tools"
source(paste(github_link,'config.local.private',sep='/'));
source(paste(hydro_tools,"VAHydro-2.0/rest_functions.R", sep = "/"));
source(paste(hydro_tools,"VAHydro-1.0/fn_vahydro-1.0.R", sep = "/"));
source(paste(hydro_tools,"LowFlow/fn_iha.R", sep = "/"));
#retrieve rest token - DISABLED
#fxn_locations <-  '/usr/local/home/git/r-dh-ecohydro/ELFGEN';
#source(paste(fxn_locations,"elf_rest_token.R", sep = "/"));
#elf_rest_token (site, token)
# to run in knit'r, need to preload token
#token = 'W-THcwwvstkINd9NIeEMrmNRls-8kVs16mMEcN_-jOA';
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
hydrocode = "vahydrosw_wshed_JU3_7490_7400";
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
# Ex: flows <- fn_get_rundata(207885, 402);
#     fn_iha_7q10(flows);
# Get data frame for stashing multirun data
stash <- data.frame();
mostash <- data.frame();
tsstash = FALSE;
featureid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = featureid,
entity_type = "dh_feature"
)
da <- getProperty(inputs, site, model)
inputs <- list(
varkey = "om_model_element",
featureid = featureid,
entity_type = "dh_feature",
propcode = "vahydro-1.0"
)
model <- getProperty(inputs, site, model)
mid = as.numeric(as.character(model[1,]$pid))
inputs <- list(
varkey = "om_element_connection",
featureid = mid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
# Manual elid
elid = as.numeric(as.character(prop[1,]$propvalue))
# Analsyis config
#runids = c(20021,20023);
#runids = c(20051,20054);
runid = 106
wshed_summary_tbl = data.frame(
"Run ID" = character(),
"Segment Name (D. Area)" = character(),
"7Q10/ALF/LF-90" = character(),
"WD (mean/max)" = character(),
stringsAsFactors = FALSE) ;
#pander(odata);
#pander(odata);
omsite = site <- "http://deq2.bse.vt.edu"
dat <- fn_get_runfile(elid, runid, site = omsite,  cached = FALSE);
library(pander);
library(httr);
library(hydroTSM);
save_directory <- "/var/www/html/files/fe/plots"
#----------------------------------------------
site <- "http://deq2.bse.vt.edu/d.dh"    #Specify the site of interest, either d.bet OR d.dh
#----------------------------------------------
# Load Libraries
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
hydro_tools <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github\\hydro-tools"
source(paste(github_link,'config.local.private',sep='/'));
source(paste(hydro_tools,"VAHydro-2.0/rest_functions.R", sep = "/"));
source(paste(hydro_tools,"VAHydro-1.0/fn_vahydro-1.0.R", sep = "/"));
source(paste(hydro_tools,"LowFlow/fn_iha.R", sep = "/"));
#retrieve rest token - DISABLED
#fxn_locations <-  '/usr/local/home/git/r-dh-ecohydro/ELFGEN';
#source(paste(fxn_locations,"elf_rest_token.R", sep = "/"));
#elf_rest_token (site, token)
# to run in knit'r, need to preload token
#token = 'W-THcwwvstkINd9NIeEMrmNRls-8kVs16mMEcN_-jOA';
source(paste(github_link,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=1200); # set timeout to twice default level to avoid abort due to high traffic
hydrocode = "vahydrosw_wshed_JU3_7490_7400";
ftype = 'vahydro'; # nhd_huc8, nhd_huc10, vahydro
inputs <- list (
hydrocode = hydrocode,
bundle = 'watershed',
ftype = 'vahydro'
)
#property dataframe returned
feature = FALSE;
odata <- getFeature(inputs, token, site, feature);
# Ex: flows <- fn_get_rundata(207885, 402);
#     fn_iha_7q10(flows);
# Get data frame for stashing multirun data
stash <- data.frame();
mostash <- data.frame();
tsstash = FALSE;
featureid <- odata[1,"hydroid"];
fname <- as.character(odata[1,]$name );
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = featureid,
entity_type = "dh_feature"
)
da <- getProperty(inputs, site, model)
inputs <- list(
varkey = "om_model_element",
featureid = featureid,
entity_type = "dh_feature",
propcode = "vahydro-1.0"
)
model <- getProperty(inputs, site, model)
mid = as.numeric(as.character(model[1,]$pid))
inputs <- list(
varkey = "om_element_connection",
featureid = mid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
# Manual elid
elid = as.numeric(as.character(prop[1,]$propvalue))
# Analsyis config
#runids = c(20021,20023);
#runids = c(20051,20054);
runid = 106
wshed_summary_tbl = data.frame(
"Run ID" = character(),
"Segment Name (D. Area)" = character(),
"7Q10/ALF/LF-90" = character(),
"WD (mean/max)" = character(),
stringsAsFactors = FALSE) ;
#pander(odata);
#pander(odata);
omsite = site <- "http://deq2.bse.vt.edu"
dat <- fn_get_runfile(elid, runid, site = omsite,  cached = FALSE);
plot(as.numeric(dat$Qout) ~ as.Date(as.character(dat$thisdate)), ylim = c(0,1000))
quantile(as.numeric(dat$Qout))
quantile(as.numeric(dat$wd_cumulative_mgd))
library(dataRetrieval)
library(lubridate)
library(plyr)
library(zoo)
library(knitr)
library(ggplot2)
library(stats)
library(lfstat)
library(rstudioapi)
library(IHA)
library(PearsonDS)
library(lfstat)
library(scales)
library(readr)
library(httr)
library(dplyr)
library(stringr)
library(RCurl)
library(rgeos)
library(ggmap)
library(ggsn)
library(sp)
library(rlist)
library(tinytex)
mod.phase1 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario1 <- 'CFBASE30Y20180615' #or "p532cal_062211" (phase 5)
mod.phase2 <- 'p6/p6_gb604' #or "p532c-sova" (phase 5)
mod.scenario2 <- 'CBASE1808L55CY55R45P50R45P50Y' #or "p532cal_062211" (phase 5)
start.date <- '1984-01-01'
end.date <- '2000-12-31'
github_link <- "C:\\Users\\Kevin D'Andrea\\Desktop\\HARP\\Github"
site_url <- "http://deq2.bse.vt.edu/d.dh"
site.or.server <- 'site'
automated_dashboard <- function(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url, site.or.server, start.num = 1, num.reps = NA) {
cbp6_link = paste0(github_link, "/cbp6/code");
setwd(cbp6_link)
#dir.create(paste0('/opt/model/p6/p6_gb604/out/dashboards/', mod.scenario1, '.vs.', mod.scenario2))
dash.output.dir <- paste0('/opt/model/p6/p6_gb604/out/dashboards/', mod.scenario1, '.vs.', mod.scenario2)
metr.output.dir <- paste0('/opt/model/p6/p6_gb604/out/metrics')
# Sourcing functions
source(paste0(cbp6_link,"/cbp6_functions.R"))
#retrieve rest token
source(paste0(github_link, "/auth.private"));
#load rest username and password, contained in auth.private file
token <- rest_token(site_url, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
info <- read.csv(paste0(cbp6_link, "/data.csv"))
if (is.na(num.reps) == TRUE) {
num.reps <- length(info$riv.seg)
}
base.table <- data.frame()
climatechange.table <- data.frame()
counter <- 279
while (counter <= num.reps) { #change to number of rows on full csv
print(paste('Generating dashboard for segment', counter, 'of', counter+num.reps, sep = ' '))
riv.seg <- as.character(info[counter,1]) #input for model data import
site_number <- paste0("0",info[counter,2]) #input for model data import
rmarkdown::render(paste0("Working_Dashboard_2019.Rmd"), "pdf_document", output_dir = dash.output.dir, output_file = paste0(riv.seg, ".pdf"),
params = list(token = token, riv.seg = riv.seg))
# LOADING DATA ------------------------------------------------------------
# if (site.or.server == 'site') {
#   data1 <- model_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
#   data2 <- model_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
# } else if (site.or.server == 'server') {
#   data1 <- model_server_import_data_cfs(riv.seg, mod.phase1, mod.scenario1, start.date, end.date)
#   data2 <- model_server_import_data_cfs(riv.seg, mod.phase2, mod.scenario2, start.date, end.date)
# }
#
# data1 <- water_year_trim(data1)
# data2 <- water_year_trim(data2)
# metrics1 <- metrics_calc_all(data1) #calculate metrics into a matrix
rownames(metrics1) <- (riv.seg)
# metrics2 <- metrics_calc_all(data2)
rownames(metrics2) <- (riv.seg)
all_metrics <- metrics_compare(metrics1, metrics2, riv.seg)
# table.metrics1 <- data.frame(riv.seg,metrics1[1,1],metrics1[1,67],metrics1[1,61],metrics1[1,59]) #create row to add to overall dataframe
# table.metrics2 <- data.frame(riv.seg,metrics2[1,1],metrics2[1,67],metrics2[1,61],metrics2[1,59]) #create row to add to overall dataframe
# colnames(table.metrics1) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
# colnames(table.metrics2) <- c('River Segment', 'Overall Mean Flow', 'Mean Baseflow', 'September 10%', '7Q10')
base.table <- rbind(base.table, metrics1, stringsAsFactors = FALSE)
climatechange.table <- rbind(climatechange.table, metrics2, stringsAsFactors = FALSE)
counter <- counter + 1
}
}
automated_dashboard(mod.phase1, mod.scenario1, mod.phase2, mod.scenario2, start.date, end.date, github_link, site_url, site.or.server, start.num = 1, num.reps = NA)
