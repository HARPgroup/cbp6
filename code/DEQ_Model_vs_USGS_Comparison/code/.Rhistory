'PU6_3752_4080','PU6_3870_3690','PU6_4020_3870','PU6_4080_4180',
'PU6_4180_4150','JA0_7291_7290','JA2_7290_0001','JA1_7600_7570',
'JA1_7640_7280','JA2_7410_7470','JA2_7550_7280','JA2_7570_7480',
'JA4_7280_7340','JA4_7340_7470','JA4_7470_7480','JA5_7480_0001',
'JB3_6820_7053','JB3_7053_0001','PL1_4460_4780','PL1_4780_0001',
'JL1_6560_6440','JL1_6760_6910','JL1_6770_6850','JL1_6910_6960',
'JL1_6940_7200','JL1_7080_7190','JL1_7170_6800','JL1_7190_7250',
'JL1_7200_7250','JL1_7530_7430','JL2_6240_6520','JL2_6440_6441',
'JL2_6441_6520','JL2_6850_6890','JL2_7110_7120','JL2_7120_6970',
'JL2_7240_7350','JL2_7250_7090','JL2_7350_7090','JL3_7020_7100',
'JL3_7090_7150','JL4_6520_6710','JL4_6710_6740','JL6_6740_7100',
'JL6_6890_6990','JL6_6960_6970','JL6_6970_6740','JL6_6990_6960',
'JL6_7150_6890','JL6_7160_7440','JL6_7320_7150','JL6_7430_7320',
'JL6_7440_7430','JL7_6800_7070','JL7_7030_6800','JL7_7070_0001',
'JL7_7100_7030','JU1_6290_6590','JU1_6300_6650','JU1_6340_6650',
'JU1_6590_6600','JU1_6880_7260','JU1_7560_7500','JU1_7630_7490',
'JU1_7690_7490','JU1_7750_7560','JU2_6410_6640','JU2_6600_6810',
'JU2_6810_6900','JU2_7140_7330','JU2_7180_7380','JU2_7360_7000',
'JU2_7450_7360','JU3_6380_6900','JU3_6640_6790','JU3_6650_7300',
'JU3_6790_7260','JU3_6900_6950','JU3_6950_7330','JU3_7400_7510',
'JU3_7490_7400','JU4_7000_7300','JU4_7260_7380','JU4_7330_7000',
'JU4_7380_7160','JU5_7300_7510','JU5_7420_7160','JU5_7500_7420',
'JU5_7510_7500','PL0_5141_5140','PL1_5370_5470','PL2_4970_5250',
'PL2_5140_5360','PL2_5470_5360','PL3_5250_0001','PL3_5360_5250',
'PL0_5010_5130','PL1_5130_0001','PL0_5490_0001','PL0_5540_5490',
'PL2_5300_5630','PL2_5630_0001','PL0_5730_5690','PL1_5690_0001',
'PL0_5530_5710','PL0_5710_0001','RU2_5220_5640','RU2_5500_5610',
'RU2_5810_5610','RU2_5940_6200','RU2_6090_6220','RU2_6200_6170',
'RU2_6220_6170','RU3_5610_5640','RU3_6170_6040','RU4_5640_6030',
'RU4_6040_6030','RU5_6030_0001','WM1_3660_3910','WM1_3910_0001',
'WM0_3881_3880','WM1_3882_3880','WM3_3880_4060','WM3_4060_0001',
'WU1_3240_3331','WU1_3330_0001','WU1_3331_3330','WU0_3021_3020',
'WU1_3350_3490','WU1_3490_3480','WU2_3020_3320','WU2_3320_3480',
'WU3_3480_3481','WU3_3481_0001','XU0_4090_4270','XU0_4091_4270',
'XU0_4130_4070','XU2_4070_4330','XU2_4270_4650','XU2_4330_4480',
'XU2_4480_4650','XU3_4650_0001','YM1_6370_6620','YM2_6120_6430',
'YM3_6430_6620','YM4_6620_0001','YP1_6570_6680','YP1_6680_6670',
'YP2_6390_6330','YP3_6330_6700','YP3_6470_6690','YP3_6670_6720',
'YP3_6690_6720','YP3_6700_6670','YP4_6720_6750','YP4_6750_0001',
'YP0_6840_0001','YP0_6860_6840')
# Splitting the River Segment string into each segment name
RivSegStr <- strsplit(RivSeg, "\\+")
RivSegStr <- RivSegStr[[1]]
num.segs <- length(RivSegStr)
# Getting all upstream segments for each of the linked segs, combining
# to form a vector of all upstream segments.
AllUpstreamSegs <- vector()
for (i in 1:num.segs) {
RivSeg <- RivSegStr[i]
UpstreamSegs <- fn_ALL.upstream(RivSeg, AllSegList)
AllUpstreamSegs <- c(AllUpstreamSegs, UpstreamSegs)
}
eliminate <- which(AllUpstreamSegs=="NA")
if (is.empty(eliminate) == FALSE) {
AllUpstreamSegs <- AllUpstreamSegs[-eliminate]
}
AllUpstreamSegs <- unique(AllUpstreamSegs)
num.upstream <- length(AllUpstreamSegs)
STATES <- read.table(file=paste(hydro_tools,"GIS_LAYERS","STATES.tsv",sep="\\"), header=TRUE, sep="\t") #Load state geometries
# first specify bounding box / extent of map: -----------------------------
extent <- data.frame(x = c(-84, -75),
y = c(35, 41))
bb=readWKT(paste0("POLYGON((",extent$x[1]," ",extent$y[1],",",extent$x[2]," ",extent$y[1],",",extent$x[2]," ",extent$y[2],",",extent$x[1]," ",extent$y[2],",",extent$x[1]," ",extent$y[1],"))",sep=""))
bbProjected <- SpatialPolygonsDataFrame(bb,data.frame("id"), match.ID = FALSE)
bbProjected@data$id <- rownames(bbProjected@data)
bbPoints <- fortify(bbProjected, region = "id")
bbDF <- merge(bbPoints, bbProjected@data, by = "id")
# specify states info: LOAD STATE GEOMETRY --------------------------------
VA <- STATES[which(STATES$state == "VA"),]
VA_geom <- readWKT(VA$geom)
VA_geom_clip <- gIntersection(bb, VA_geom)
VAProjected <- SpatialPolygonsDataFrame(VA_geom_clip,data.frame("id"), match.ID = TRUE)
VAProjected@data$id <- rownames(VAProjected@data)
VAPoints <- fortify( VAProjected, region = "id")
VADF <- merge(VAPoints,  VAProjected@data, by = "id")
TN <- STATES[which(STATES$state == "TN"),]
TN_geom <- readWKT(TN$geom)
TN_geom_clip <- gIntersection(bb, TN_geom)
TNProjected <- SpatialPolygonsDataFrame(TN_geom_clip,data.frame("id"), match.ID = TRUE)
TNProjected@data$id <- rownames(TNProjected@data)
TNPoints <- fortify( TNProjected, region = "id")
TNDF <- merge(TNPoints,  TNProjected@data, by = "id")
NC <- STATES[which(STATES$state == "NC"),]
NC_geom <- readWKT(NC$geom)
NC_geom_clip <- gIntersection(bb, NC_geom)
NCProjected <- SpatialPolygonsDataFrame(NC_geom_clip,data.frame("id"), match.ID = TRUE)
NCProjected@data$id <- rownames(NCProjected@data)
NCPoints <- fortify( NCProjected, region = "id")
NCDF <- merge(NCPoints,  NCProjected@data, by = "id")
KY <- STATES[which(STATES$state == "KY"),]
KY_geom <- readWKT(KY$geom)
KY_geom_clip <- gIntersection(bb, KY_geom)
KYProjected <- SpatialPolygonsDataFrame(KY_geom_clip,data.frame("id"), match.ID = TRUE)
KYProjected@data$id <- rownames(KYProjected@data)
KYPoints <- fortify( KYProjected, region = "id")
KYDF <- merge(KYPoints,  KYProjected@data, by = "id")
WV <- STATES[which(STATES$state == "WV"),]
WV_geom <- readWKT(WV$geom)
WV_geom_clip <- gIntersection(bb, WV_geom)
WVProjected <- SpatialPolygonsDataFrame(WV_geom_clip,data.frame("id"), match.ID = TRUE)
WVProjected@data$id <- rownames(WVProjected@data)
WVPoints <- fortify( WVProjected, region = "id")
WVDF <- merge(WVPoints,  WVProjected@data, by = "id")
MD <- STATES[which(STATES$state == "MD"),]
MD_geom <- readWKT(MD$geom)
MD_geom_clip <- gIntersection(bb, MD_geom)
MDProjected <- SpatialPolygonsDataFrame(MD_geom_clip,data.frame("id"), match.ID = TRUE)
MDProjected@data$id <- rownames(MDProjected@data)
MDPoints <- fortify( MDProjected, region = "id")
MDDF <- merge(MDPoints,  MDProjected@data, by = "id")
DE <- STATES[which(STATES$state == "DE"),]
DE_geom <- readWKT(DE$geom)
DE_geom_clip <- gIntersection(bb, DE_geom)
DEProjected <- SpatialPolygonsDataFrame(DE_geom_clip,data.frame("id"), match.ID = TRUE)
DEProjected@data$id <- rownames(DEProjected@data)
DEPoints <- fortify( DEProjected, region = "id")
DEDF <- merge(DEPoints,  DEProjected@data, by = "id")
PA <- STATES[which(STATES$state == "PA"),]
PA_geom <- readWKT(PA$geom)
PA_geom_clip <- gIntersection(bb, PA_geom)
PAProjected <- SpatialPolygonsDataFrame(PA_geom_clip,data.frame("id"), match.ID = TRUE)
PAProjected@data$id <- rownames(PAProjected@data)
PAPoints <- fortify( PAProjected, region = "id")
PADF <- merge(PAPoints,  PAProjected@data, by = "id")
NJ <- STATES[which(STATES$state == "NJ"),]
NJ_geom <- readWKT(NJ$geom)
NJ_geom_clip <- gIntersection(bb, NJ_geom)
NJProjected <- SpatialPolygonsDataFrame(NJ_geom_clip,data.frame("id"), match.ID = TRUE)
NJProjected@data$id <- rownames(NJProjected@data)
NJPoints <- fortify( NJProjected, region = "id")
NJDF <- merge(NJPoints,  NJProjected@data, by = "id")
OH <- STATES[which(STATES$state == "OH"),]
OH_geom <- readWKT(OH$geom)
OH_geom_clip <- gIntersection(bb, OH_geom)
OHProjected <- SpatialPolygonsDataFrame(OH_geom_clip,data.frame("id"), match.ID = TRUE)
OHProjected@data$id <- rownames(OHProjected@data)
OHPoints <- fortify( OHProjected, region = "id")
OHDF <- merge(OHPoints,  OHProjected@data, by = "id")
SC <- STATES[which(STATES$state == "SC"),]
SC_geom <- readWKT(SC$geom)
SC_geom_clip <- gIntersection(bb, SC_geom)
SCProjected <- SpatialPolygonsDataFrame(SC_geom_clip,data.frame("id"), match.ID = TRUE)
SCProjected@data$id <- rownames(SCProjected@data)
SCPoints <- fortify( SCProjected, region = "id")
SCDF <- merge(SCPoints,  SCProjected@data, by = "id")
DC <- STATES[which(STATES$state == "DC"),]
DC_geom <- readWKT(DC$geom)
DC_geom_clip <- gIntersection(bb, DC_geom)
DCProjected <- SpatialPolygonsDataFrame(DC_geom_clip,data.frame("id"), match.ID = TRUE)
DCProjected@data$id <- rownames(DCProjected@data)
DCPoints <- fortify( DCProjected, region = "id")
DCDF <- merge(DCPoints,  DCProjected@data, by = "id")
# set up ggplot for states ---------------
statemap <- ggplot(data = VADF, aes(x=long, y=lat, group = group))+
geom_polygon(data = bbDF, color="black", fill = "powderblue",lwd=0.5)+
geom_polygon(data = VADF, color="gray46", fill = "gray")+
geom_polygon(data = TNDF, color="gray46", fill = "gray", lwd=0.5)+
geom_polygon(data = NCDF, color="gray46", fill = "gray", lwd=0.5)+
geom_polygon(data = SCDF, color="gray46", fill = "gray", lwd=0.5)+
geom_polygon(data = KYDF, color="gray46", fill = "gray", lwd=0.5)+
geom_polygon(data = WVDF, color="gray46", fill = "gray", lwd=0.5)+
geom_polygon(data = MDDF, color="gray46", fill = "gray", lwd=0.5)+
geom_polygon(data = DEDF, color="gray46", fill = "gray", lwd=0.5)+
geom_polygon(data = PADF, color="gray46", fill = "gray", lwd=0.5)+
geom_polygon(data = NJDF, color="gray46", fill = "gray", lwd=0.5)+
geom_polygon(data = OHDF, color="gray46", fill = "gray", lwd=0.5)+
geom_polygon(data = DCDF, color="gray46", fill = "gray", lwd=0.5)
if (num.upstream > 0) {
for (i in 1:num.upstream) {
RivSeg <- AllUpstreamSegs[i]
namer <- paste0("upstream.watershedDF", i)
# Retrieve Riversegment Feature From VAHydro  -----------------------------
inputs <- list (
bundle = 'watershed',
ftype = 'vahydro',
hydrocode = paste0('vahydrosw_wshed_', RivSeg)
)
dataframe <- getFeature(inputs, token, site)
#print(dataframe)
hydroid <- dataframe$hydroid
inputs <- list(
varkey = "wshed_drainage_area_sqmi",
featureid = hydroid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = hydroid,
entity_type = "dh_feature"
)
local_da_prop <- getProperty(inputs, site, prop)
#postProperty(inputs = local_da_prop, base_url = site, prop = prop)
geom <- dataframe$geom
watershedDF <- getWatershedDF(geom)
assign(namer, watershedDF)
}
}
for (i in 1:num.segs) {
RivSeg <- RivSegStr[i]
namer <- paste0("seg.watershedDF", i)
# Retrieve Riversegment Feature From VAHydro  -----------------------------
inputs <- list (
bundle = 'watershed',
ftype = 'vahydro',
hydrocode = paste0('vahydrosw_wshed_', RivSeg)
)
dataframe <- getFeature(inputs, token, site)
#print(dataframe)
hydroid <- dataframe$hydroid
inputs <- list(
varkey = "wshed_drainage_area_sqmi",
featureid = hydroid,
entity_type = "dh_properties"
)
prop <- getProperty(inputs, site, prop)
inputs <- list(
varkey = "wshed_local_area_sqmi",
featureid = hydroid,
entity_type = "dh_feature"
)
local_da_prop <- getProperty(inputs, site, prop)
#postProperty(inputs = local_da_prop, base_url = site, prop = prop)
geom <- dataframe$geom
watershedDF <- getWatershedDF(geom)
assign(namer, watershedDF)
}
modelinput <- list(
varkey = "om_model_element",
featureid = local_da_prop$featureid,
entity_type = "dh_feature",
propcode = "p532cal_062211"
)
findgage <- getProperty(modelinput, site, findgage)
gageexist <- list(
varkey = "gage_weighted",
featureid = findgage$pid,
entity_type = "dh_properties"
)
gagetrue <- getProperty(gageexist, site, gagetrue)
# if gagetrue is not logical, analyze with gages, check for linked segments.
if (is.logical(gagetrue)==TRUE){
# Retrieve USGS Gage Feature From VAHydro  --------------------------------
Gage <- as.character(siteNo)
gage.inputs <- list (
bundle = 'usgsgage',
hydrocode = paste0('usgs_', Gage)
)
gage.df <- getFeature(gage.inputs, token, site)
# Set up gage geometry:
# Geoprocess gage geometry----------------------
split_1 <- read.table(text = as.character(gage.df$geom), sep = "(", colClasses = "character")
split_2 <- read.table(text = split_1$V2, sep = ")", colClasses = "character")
split_3 <- read.table(text = split_2$V1, sep = " ", colClasses = "character")
GAGEDF <- data.frame(x=as.numeric(split_3$V1),y=as.numeric(split_3$V2),X.id.="id",id="1")
}
split_1
split_2
split_3
GAGEDF
# Create gage dataframe (gage_linked?) ---------------------
library(dataRetrieval)
gage <- readNWISsite(siteNo)
View(gage)
# Create gage dataframe (gage_linked?) ---------------------
library(dataRetrieval)
gage <- readNWISsite(siteNo)
GAGEDF <- data.frame(x=as.numeric(gage$dec_long_va),y=as.numeric(gage$dec_lat_va),X.id.="id",id="1")
GAGEDF
# INPUTS ------------------------------------------------------------------
# Link to hydro-tools folder within GitHub folder
basepath='C:\\Users\\danie\\Downloads\\Downloads\\HARP\\GitHub\\hydro-tools';
# Address of "DEQ_Model_vs_USGS_Comparison" folder
# Include "DEQ_Model_vs_USGS_Comparison" in address!
container <- paste0(basepath, "\\HARP-2018\\DEQ_Model_vs_USGS_Comparison_Northern")
# USGS Gage number
siteNo <- "02011400"
# CARRYOVER IF MASTER IS BEING RUN ----------------------------------------
if (exists("container.master") == TRUE) {
container <- container.master
siteNo <- siteNo.master
new.or.original <- new.or.original.master
}
# LINKING MODEL SEGMENT ---------------------------------------------------
gage.to.segment <- read.csv(file.path(container, "data", "Gage_To_Segment_Northern.csv"),
header = TRUE, sep = ',', stringsAsFactors = FALSE)
# INPUTS ------------------------------------------------------------------
# Link to hydro-tools folder within GitHub folder
basepath='C:\\Users\\danie\\Downloads\\Downloads\\HARP\\GitHub\\hydro-tools';
# Address of "DEQ_Model_vs_USGS_Comparison" folder
# Include "DEQ_Model_vs_USGS_Comparison" in address!
container <- paste0(basepath, "\\HARP-2018\\DEQ_Model_vs_USGS_Comparison_Northern")
# USGS Gage number
siteNo <- "02011400"
# CARRYOVER IF MASTER IS BEING RUN ----------------------------------------
if (exists("container.master") == TRUE) {
container <- container.master
siteNo <- siteNo.master
new.or.original <- new.or.original.master
}
gage.to.segment <- read.csv(file.path(container, "data", "Gage_To_Segment_Northern.csv"),
header = TRUE, sep = ',', stringsAsFactors = FALSE)
file.path(container, "data", "Gage_To_Segment_Northern.csv")
# INPUTS ------------------------------------------------------------------
# Link to hydro-tools folder within GitHub folder
basepath='C:\\Users\\danie\\Documents\\HARP\\GitHub\\hydro-tools';
# Address of "DEQ_Model_vs_USGS_Comparison" folder
# Include "DEQ_Model_vs_USGS_Comparison" in address!
container <- paste0(basepath, "\\HARP-2018\\DEQ_Model_vs_USGS_Comparison_Northern")
# USGS Gage number
siteNo <- "01621410"
# CARRYOVER IF MASTER IS BEING RUN ----------------------------------------
if (exists("container.master") == TRUE) {
container <- container.master
siteNo <- siteNo.master
new.or.original <- new.or.original.master
}
# LINKING MODEL SEGMENT ---------------------------------------------------
gage.to.segment <- read.csv(file.path(container, "data", "Gage_To_Segment_Northern.csv"),
header = TRUE, sep = ',', stringsAsFactors = FALSE)
gage.to.segment <- subset(gage.to.segment, gage.to.segment$gage == as.numeric(siteNo))
RivSeg <- gage.to.segment$segment
```
# INPUTS ------------------------------------------------------------------
# Link to hydro-tools folder within GitHub folder
basepath='C:\\Users\\danie\\Documents\\HARP\\GitHub\\hydro-tools';
# Address of "DEQ_Model_vs_USGS_Comparison" folder
# Include "DEQ_Model_vs_USGS_Comparison" in address!
container <- paste0(basepath, "\\HARP-2018\\DEQ_Model_vs_USGS_Comparison_Northern")
# USGS Gage number
siteNo <- "01621410"
# CARRYOVER IF MASTER IS BEING RUN ----------------------------------------
if (exists("container.master") == TRUE) {
container <- container.master
siteNo <- siteNo.master
new.or.original <- new.or.original.master
}
gage.to.segment <- read.csv(file.path(container, "data", "Gage_To_Segment_Northern.csv"),
header = TRUE, sep = ',', stringsAsFactors = FALSE)
gage.to.segment <- subset(gage.to.segment, gage.to.segment$gage == as.numeric(siteNo))
RivSeg <- gage.to.segment$segment
gage.to.segment <- read.csv(file.path(container, "data", "Gage_To_Segment_Northern.csv"),
header = TRUE, sep = ',', stringsAsFactors = FALSE)
gage.to.segment <- subset(gage.to.segment, gage.to.segment$gage == as.numeric(siteNo))
RivSeg <- gage.to.segment$segment
```
# Should new or original data be used?
new.or.original <- "new"
site <- "http://deq2.bse.vt.edu/d.dh"    #Specify the site of interest, either d.bet OR d.dh
source(paste(basepath,'config.local.private',sep='/'));
source(paste(hydro_tools,"VAHydro-2.0/rest_functions.R", sep = "/"));
#source(paste(hydro_tools, "HARP-2018/DEQ_Model_vs_USGS_Comparison_Northern/code/fn_gage+seg_mapper.R", sep = "/"));
source(paste(hydro_tools, "HARP-2018/DEQ_Model_vs_USGS_Comparison_Northern/code/fn_gage+seg_mapper_fromNWIS.R", sep = "/"));
#retrieve rest token
source(paste(hydro_tools,"auth.private", sep = "/"));#load rest username and password, contained in auth.private file
token <- rest_token(site, token, rest_uname, rest_pw);
options(timeout=120); # set timeout to twice default level to avoid abort due to high traffic
```{r error, include=FALSE}
library(zoo)
library(lubridate)
library(knitr)
library(ggplot2)
library(readr)
library(magick)
if (new.or.original == "new") {
container.cont <- "\\data\\new_(updated)_data"
} else if (new.or.original == "original") {
container.cont <- "\\data\\original_(reproducible)_data"
} else {
print("ERROR: neither new or original data specified")
}
description <- read_file(paste0(container, "\\gage_descriptions\\", siteNo, ".txt"))
# TEXT ------
data <- read.csv(paste0(container, container.cont, "\\derived_data\\trimmed+area-adjusted_data\\",siteNo,"_vs_",RivSeg, " - Derived Data.csv"))
# GIS ------
# Generating gage location maps
gis_img <- fn_gage_and_seg_mapper(RivSeg, siteNo, site, hydro_tools, token)
# OVERALL MEAN FLOW
met00_Gage_MeanFlow <- signif(mean(data$gage.flow), digits=3);
met00_Model_MeanFlow <- signif(mean(data$model.flow), digits=3);
met00_PctError <- -(signif(((met00_Model_MeanFlow - met00_Gage_MeanFlow) / met00_Gage_MeanFlow)*100, digits=3));
# Calculating mean flow of gage and model
avg_gage <- mean(data$gage.flow)
avg_model <- mean(data$model.flow)
# ADDING ADDITIONAL DATA COLUMNS ------------------------------------------
data$year <- year(ymd(data$date))
data$month <- month(ymd(data$date))
data$day <- day(ymd(data$date))
data$date <- as.Date(data$date)
start.date <- data$date[1]
# DOCUMENTATION -----------------------------------------------------------
# Creates plots zoomed in three-month periods of highest error, also calculates
# a few metrics pertaining to error -- such as percent of observations above 20%
library(zoo)
library(lubridate)
library(knitr)
library(ggplot2)
library(readr)
library(magick)
# INPUTS ----------------------------------------------------
# NEW OR ORIGINAL DATA SWITCH ---------------------------------------------
if (new.or.original == "new") {
container.cont <- "\\data\\new_(updated)_data"
} else if (new.or.original == "original") {
container.cont <- "\\data\\original_(reproducible)_data"
} else {
print("ERROR: neither new or original data specified")
}
# LOADING DATA ------------------------------------------------------------
description <- read_file(paste0(container, "\\gage_descriptions\\", siteNo, ".txt"))
# TEXT ------
data <- read.csv(paste0(container, container.cont, "\\derived_data\\trimmed+area-adjusted_data\\",siteNo,"_vs_",RivSeg, " - Derived Data.csv"))
# GIS ------
# Generating gage location maps
gis_img <- fn_gage_and_seg_mapper(RivSeg, siteNo, site, hydro_tools, token)
# OVERALL MEAN FLOW
met00_Gage_MeanFlow <- signif(mean(data$gage.flow), digits=3);
met00_Model_MeanFlow <- signif(mean(data$model.flow), digits=3);
met00_PctError <- -(signif(((met00_Model_MeanFlow - met00_Gage_MeanFlow) / met00_Gage_MeanFlow)*100, digits=3));
# Calculating mean flow of gage and model
avg_gage <- mean(data$gage.flow)
avg_model <- mean(data$model.flow)
# ADDING ADDITIONAL DATA COLUMNS ------------------------------------------
data$year <- year(ymd(data$date))
data$month <- month(ymd(data$date))
data$day <- day(ymd(data$date))
data$date <- as.Date(data$date)
start.date <- data$date[1]
end.date <- data$date[length(data$date)]
DumYear <- data.frame(as.Date(seq(as.Date(start.date), as.Date(end.date), by = 'day')))
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/data_downloader.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/data_prepper.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/data_prepper.R', echo=TRUE)
current_path
basepath
container
basepath <- paste0(split.location[1:basepath.stop], collapse = "/")
container <- paste0(basepath,"DEQ_Model_vs_USGS_Comparison")
basepath
container
# Setting up output location
split.location <- strsplit(current_path, split = '/')
split.location <- as.vector(split.location[[1]])
basepath.stop <- as.numeric(which(split.location == 'code'))
basepath <- paste0(split.location[1:basepath.stop], collapse = "/")
container <- paste0(basepath,"DEQ_Model_vs_USGS_Comparison")
container
basepath
# Setting active directory
# Setting working directory to the source file location
current_path <- rstudioapi::getActiveDocumentContext()$path
# Setting up output location
split.location <- strsplit(current_path, split = '/')
split.location <- as.vector(split.location[[1]])
basepath.stop <- as.numeric(which(split.location == 'code'))
basepath <- paste0(split.location[1:basepath.stop], collapse = "/")
basepath
basepath
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/data_prepper.R', echo=TRUE)
library('lubridate')
library('dataRetrieval')
# Setting active directory
# Setting working directory to the source file location
current_path <- rstudioapi::getActiveDocumentContext()$path
# Setting up output location
split.location <- strsplit(current_path, split = '/')
split.location <- as.vector(split.location[[1]])
basepath.stop <- as.numeric(which(split.location == 'code'))
basepath <- paste0(split.location[1:basepath.stop], collapse = "/")
container <- paste0(basepath,"/DEQ_Model_vs_USGS_Comparison")
# INPUTS ------------------------------------------------------------------
# USGS Gage number
siteNo <- "02037500"
# Should new or original data be used?
new.or.original <- "new"
site <- "http://deq2.bse.vt.edu/d.bet"    #Specify the site of interest, either d.bet OR d.dh
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/data_prepper.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/metric_calculator.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/data_downloader.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/data_prepper.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/data_prepper.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/data_prepper.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/metric_calculator.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/master_RUN_ALL.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/error_calculator.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/plot_creator.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/master_RUN_ALL.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/master_RUN_ALL.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/master_RUN_ALL.R', echo=TRUE)
rm(list = ls())
library(rmarkdown)
# Setting active directory
# Setting working directory to the source file location
current_path <- rstudioapi::getActiveDocumentContext()$path
# Setting up output location
split.location <- strsplit(current_path, split = '/')
split.location <- as.vector(split.location[[1]])
basepath.stop <- as.numeric(which(split.location == 'DEQ_Model_vs_USGS_Comparison'))
container.master <- paste0(split.location[1:basepath.stop], collapse = "/")
# USGS Gage number
# If "all" is inputted as siteNo.master, analysis will be run for ALL gages
# stored in the Gage.To.Segment.csv file.
siteNo.master <- "all"
mod.phase.master <- "p6/p6_gb604/tmp" # should be "p6/p6_gb604/tmp" (phase 6) or "p532c-sova" (phase 5)
mod.scenario.master <- "CFBASE30Y20180615" # should be "CFBASE30Y20180615" (phase 6) or "p532cal_062211"
# Should new or original data be used?
new.or.original.master <- "new"
gage.to.segment <- read.csv(file.path(container.master, "data", "Gage_To_Segment.csv"),
header = TRUE, sep = ',', stringsAsFactors = FALSE)
View(gage.to.segment)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/master_RUN_ALL.R', echo=TRUE)
source('~/HARP/GitHub/cbp6/code/DEQ_Model_vs_USGS_Comparison/code/master_RUN_ALL.R', echo=TRUE)
